\chapter{Fundamentos teóricos} \label{chap-FT}

Este capítulo apresenta a fundamentação teórica necessária para estudo na área de otimização combinatória, com ênfase nos métodos de resolução de problemas, bem como o estudo da teoria de escalonamento.

Dessa forma, são apresentados os conceitos e os principais problemas de otimização combinatória, incluindo seus principais métodos de resolução (exatos e aproximados). A teoria de escalonamento, que se propõe a conceituar, classificar e apresentar modelos teóricos, notações e políticas de escalonamento, é também resumida neste capítulo. As seções seguintes abordam os tópicos citados acima.


\section{Otimização combinatória}

Otimização Combinatória é uma área de pesquisa que trata um tipo especial de problema de otimização matemática cujo conjunto de soluções factíveis pode ser representado por um espaço de busca discreto. Onde se deseja encontrar, dentre todas as possíveis soluções, aquela solução (ou soluções) cujo custo maximize ou minimize uma determinada função objetivo (ou múltiplos objetivos), respeitando um determinado conjunto de restrições~\cite{marti2011linear} \cite{rodrigues:1996}. Dependendo da complexidade do problema, uma forma de solucionar seria simplesmente enumerar todas as soluções possíveis e retornar a melhor delas. Entretanto, para problemas com um espaço de busca exponencial, este método torna-se impraticável, o que desperta cada vez mais a atenção de pesquisadores da área em propor modelos teóricos mais robustos e métodos mais eficientes, a fim de obter melhores resultados em tempo de execução adequado.

Os problemas de Otimização Combinatória surgem nos mais diversos contextos e, certamente, em todas as áreas tecnológicas, de logística e de gestão industrial~\cite{Lawler:2001}. Um grande número de problemas de otimização combinatória ocorre em projetos de sistemas de distribuição e alocação de recursos, projetos de redes de computadores, roteamento de veículos, escalonamento de tarefas em máquinas, empacotamento de caixas em contêineres, cortes em placas ou madeira, sequenciamento de genes e DNA, modelagem molecular, localização e alocação de canais em redes de sensores sem fio, dentre outros. Estes problemas exigem, cada vez mais, novas abordagens e métodos, envolvendo novas ideias teóricas, matemático-computacionais, para serem solucionados de maneira eficiente ~\cite{MullerMerbach:1981}. 

Estes problemas podem ser classificados quanto a sua complexidade computacional, o que permite a separação dos problemas fáceis dos difíceis. Todos os problemas de otimização combinatória possuem uma versão de decisão, onde suas soluções consistem em uma resposta positiva (sim) ou negativa (não) para um determinado questionamento quanto a existência de alguma solução. A classificação de tais problemas é feita através da \textbf{Teoria da NP-Completude}, onde o problema é tratado como um conjunto de parâmetros (definição das instâncias) e um conjunto do propriedades (restrições do problema). Para as instâncias de um mesmo problema, as únicas variações estão nos conjuntos de parâmetros. A teoria da complexidade considera o tamanho das instâncias como sendo a quantidade de \textit{bits} necessária para representá-las em computadores digitais~\cite{GareyJohnson:1979}. 

De um modo geral, os problemas de interesse neste trabalho envolvem problemas de Otimização Combinatória conhecidos como NP-Difíceis, que são aqueles para os quais não se conhece nenhum algoritmo que retorne a solução ótima em tempo polinomial e sim, apenas algoritmos de tempo de execução exponencial, o que é considerado intratável do ponto de vista computacional, dado que para grandes instâncias pode se tornar completamente inviável obter todas as soluções possíveis ou gerar a melhor solução para o problema.

Nas próximas subseções, serão detalhados os métodos de resolução de problemas de Otimização Combinatória, sendo divididos em exatos (Subseção \ref{subsec:ME}) e aproximados (Subseção \ref{subsec:MA}). Métodos exatos são todos aqueles que devolvem a melhor solução possível - solução ótima - para o problema que está sendo resolvido \cite{rodrigues:1996}. Métodos aproximados são aqueles que, de modo geral, devolvem uma solução válida para o problema sem a garantia de que seja a melhor solução possível e, neste caso, podem ser determinísticos (maioria das heurísticas simples) ou estocásticos (meta-heurísticas e outros métodos que fazem uso de aleatoriedade e processos estocásticos) \cite{rodrigues:1996}. Dentre os métodos aproximados, existem também os chamados algoritmos aproximativos, que são aqueles que devolvem uma solução aproximada cuja razão de aproximação da solução ótima é conhecida. Esta seção baseia-se nas seguintes referências: Rodrigues~\cite{rodrigues:1996},  Rodrigues~\cite{rodrigues:2009}, Talbi~\cite{Talbi:2009} e Luke~\cite{Luke2009Metaheuristics}.


\subsection{Métodos exatos} \label{subsec:ME}

Os métodos exatos possuem a característica de fornecerem a solução ótima para um problema de Otimização Combinatória, dada a especificação do problema expressa através de um modelo teórico. Geram sempre a melhor solução possível, mas, se o problema for NP-difícil, não garantem a resolução em um tempo computacional adequado, sendo de tempo exponencial no geral. O método mais intuitivo seria um procedimento de \textbf{enumeração explícita} (de \textbf{busca exaustiva} ou, popularmente chamado de \textbf{força bruta}), que consiste em enumerar explicitamente todas as possibilidades de solução do problema e, então, escolher a melhor solução encontrada \cite{rodrigues:1996}. 

No entanto, a busca exaustiva é inviável computacionalmente para os problemas NP-difíceis de grande porte. Desta forma, na tentativa de tornar o processo algorítmico menos custoso,  métodos de enumeração implícita são utilizados, consistindo em usar modelos teóricos mais robustos e estratégias algorítmicas mais sofisticadas para uma resolução mais rápida do problema, gerando-se a solução ótima, mas sem ter o custo de se gerar todas as soluções explicitamente. Dentre tais métodos de enumeração implícita, os mais clássicos e aplicados são: programação dinâmica, \textit{branch-and-bound}, métodos de corte e de geração de colunas, \textit{branch-and-cut}, \textit{branch-and-price} e combinações entre os mesmos \cite{rodrigues:1996}.

O método exato desenvolvido no trabalho foi um \textit{branch-and-cut}, através da ferramenta CPLEX. Assim, nas seções seguintes tal método é brevemente descrito e, para um melhor entendimento do mesmo, os métodos de \textit{branch-and-bound} e de cortes no plano em geral, são brevemente descritos.


\subsubsection{\textit{Branch-and-bound}}

O método \textit{branch-and-bound} também adota uma estratégia de \textbf{enumeração implícita} para a resolução de problemas de Otimização Combinatória. A ideia básica consiste em um particionamento inteligente do espaço de busca (que pode ser representado por uma árvore), descartando partes que não poderão fornecer a solução ótima para o problema~\cite{Papadimitriou:1982}. A divisão do problema corresponde ao processo de enumerar as possibilidades válidas ou simplesmente ramificação  (do inglês, \textit{branching}), combinada com o processo de verificação do valor da função objetivo que se baseia em limites inferiores e superiores para o problema (do inglês, \textit{bounding}), e que deste modo, pode desconsiderar a ramificação por subárvores que matematicamente não produzirão valores melhores do que os já obtidos.

Dessa forma, seja um problema de minimização $P$. Os subproblemas de $P$ são os subconjuntos $S'$ do conjunto $S$ de soluções viáveis de $P$. Sendo assim, a partir do problema original $P$, pode-se estabelecer um limite inferior para o problema desconsiderando-se a restrição de integralidade e, então, o problema relaxado (relaxação linear) é resolvido com um método de solução de programação linear contínua, como o Simplex. Se a solução obtida for inteira (todas as variáveis de decisão forem inteiras na solução do Simplex), então, considera-se o problema resolvido. Caso contrário, consideram-se os seguintes passos~\cite{brucker:2006}:

\begin{itemize}
   \item \textbf{Ramificação (\textit{branching:})} $S$ é substituído por problemas menores $S_{i}(i = 1, ..., n)$. Este processo é chamado de \textbf{ramificação} (\textit{branching}), que trata-se de um processo recursivo, ou seja, $S_{i}$ é a base de outra ramificação. Todo o processo é representado por uma \textbf{árvore de ramificações} (\textit{branching tree}), onde $S$ é a raiz da árvore de ramificação e $S_{i}(i = 1, ..., n)$ são os filhos de $S$. Os ramos da árvore recebem restrições incorporadas pelo processo de ramificação, sobre uma variável de decisão $x_{i}$ (ramificações com restrições $x_{i} \le n$ e $x_{i} \ge n + 1$, por exemplo), esses ramos são chamados de \textbf{subproblemas} (Figura~\ref{fig:BB});
   \item \textbf{Definição dos limites (\textit{boundings}):} no processo de ramificação pode-se chegar nas seguintes situações nos subproblemas:
        \begin{enumerate}
            \item \textbf{A restrição adicionada torna o problema inviável:} assim não há mais ramificação a partir deste nó (o nó é \textbf{podado});
            \item \textbf{A solução do nó é inteira:} não haverá mais ramificação a partir deste nó e a solução deste nó será a melhor solução inteira atual, onde, a partir daí, é analisado se esta for a primeira melhor solução inteira, ela passará a ser um \textbf{limite superior} do problema original de minimização (ou inferior se for de maximização), ou seja, se as próximas soluções encontradas forem maiores que esta, não haverá ramificação (também serão podados). Se já houver um limite superior e se a nova solução obtida for menor que o limite superior armazenado, a nova solução passará a ser o novo limite superior do problema de minimização $P$.
        \end{enumerate}
   \item Quando não for mais possível ramificar, o último limite superior armazenado é a solução ótima do problema de programação inteira.
\end{itemize}

O método \textit{branch-and-bound} termina quando todos os subproblemas tiverem sido resolvidos. A escolha de bons algoritmos para o cálculo dos limites inferiores e superiores é crucial, justamente para que se possa eliminar uma grande parte do conjunto de soluções factíveis sem precisar enumerá-las~\cite{rodrigues:1996}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{./imagens/BB.eps}
\caption{Ramificação da árvore de \textit{branch-and-bound} para um conjunto de soluções $S$.}
\label{fig:BB}
\end{figure}


\subsubsection{Planos de corte}

Um plano de corte define uma restrição a mais para o problema, eliminando assim pontos extremos contínuos, sem remover nenhum ponto inteiro factível. Algoritmos de cortes no plano (\textit{cutting plane algorithms}) iniciam  seu processamento através de uma relaxação linear do problema e a partir daí, novas desigualdades (cortes no plano) vão sendo adicionadas ao problema relaxado. O objetivo é colocar a solução ótima do problema de programação inteira como um vértice do politopo, de forma que um método de solução, como o Simplex, possa encontrar e retornar a solução.

A partir de uma solução contínua da relaxação do problema, pode-se utilizar esses dados para criar uma nova restrição que corta pontos contínuos do politopo. Este processo de adicionar cortes que não excluam pontos inteiros viáveis do problema é ilustrado na Figura~\ref{fig:Cutting-planes}~\cite{Papadimitriou:1982}. A Figura~\ref{fig:Cutting-planes} (a) apresenta o problema de programação inteira e a solução ótima contínua $x^{*}$. Uma restrição linear, corte no plano (ou simplesmente corte), é adicionado na Figura~\ref{fig:Cutting-planes} (b), modificando assim o conjunto de soluções viáveis do problema (sem a perda de pontos inteiros) e o novo ótimo contínuo é movido de lugar. A Figura~\ref{fig:Cutting-planes} (c) apresenta o resultado após a adição de outro plano de corte, o efeito agora é fazer o ótimo contínuo virar uma solução inteira para o problema.

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/Cutting-planes.eps}
\caption{Ilustração do algoritmo de cortes no plano: (a) solução ótima contínua $x^{*}$. (b) nova solução ótima contínua $x^{*}$ após um corte. (c) solução do problema de programação inteira após dois cortes~\cite{Papadimitriou:1982}.}
\label{fig:Cutting-planes}
\end{figure}

A inequação adicionada no problema relaxado é chamada de \textbf{Cortes}. A aplicação repetida destes cortes no problema relaxado garante chegar no ponto ótimo do problema, conforme mostrado na Figura~\ref{fig:Cutting-planes}.


\subsubsection{\textit{Branch-and-cut}}

O método \textit{branch-and-cut} (B$\&$C) é um método exato de programação linear inteira, proposto por Padberg e Rinaldi~\cite{Padberg:1987} e aplicado inicialmente para solucionar o problema do caixeiro viajante. Este algoritmo combina os métodos \textit{branch-and-bound} e planos de corte. Apesar de ambos serem capazes de solucionar um problema de programação linear inteira, eles levam um certo tempo para encontrar uma solução ótima. Dessa forma, através da combinação dos dois métodos é possível diminuir esse tempo. A cada nó da árvore, busca-se o máximo de cortes que podem ser inseridos em um tempo razoável, reduzindo assim o limite superior do nó e, consequentemente, reduzindo também o tamanho da árvore de \textit{branch-and-bound}, onde os cortes podem ser controlados por algum critério, tais como:

\begin{itemize}
   \item Realizar $n$ cortes de Gomory a cada nó;
   \item Adicionar inequações específicas do problema original;
   \item Efetuar cortes a cada nível da árvore que seja múltiplo de algum valor.
\end{itemize}

No \textit{branch-and-cut} também consideram-se os cortes nos estágios de enumeração da árvore de pesquisa. Assim, através desta abordagem, é possível que se guarde uma restrição necessária para um nó de uma determinada sub-árvore, de modo elas sejam válidas para os nós de outras sub-árvores da árvore de pesquisa. O procedimento é iniciado com a relaxação do problema de programação inteira, então o problema relaxado é resolvido e se a solução violar as restrições de integralidade do problema original, o corte é aplicado (adiciona-se mais uma restrição). O objetivo é achar a solução ótima do problema sem que todas as restrições do problema original sejam adicionadas no problema relaxado.

Também existem técnicas de pré-processamento, onde tenta-se melhorar a relaxação linear através de considerações algébricas, onde variáveis e restrições são checadas para evitar redundância, alguns coeficientes de restrições são ajustados e algumas variáveis são fixadas a certos valores, sem que isto afete o valor da solução ótima do problema. Assim, é possível reduzir o número de variáveis significativamente, tornando o problema mais fácil de se resolver. Métodos heurísticos podem ser aplicados a fim de que se obtenha boas soluções, em um curto espaço de tempo, e assim reduzir o tamanho da árvore de busca do \textit{branch-and-cut}~\cite{rodrigues:1996}.


\subsection{Métodos aproximados} \label{subsec:MA}

Os métodos aproximados para resolução de problemas de otimização combinatória, ao contrário dos métodos exatos, não garantem a obtenção de uma solução ótima para o problema, mas tentam gerar uma boa solução para o problema (ou até mesmo ser a ótima) podendo ter um tempo computacional relativamente menor do que os métodos exatos, em alguns casos. Esta característica, de gerar boas soluções viáveis rapidamente, e sem precisar manipular modelos teóricos complicados, faz com que tais métodos sejam muito utilizados na resolução de problemas de Otimização Combinatória, principalmente em grandes aplicações reais.

Nas próximas subseções são abordados os principais métodos heurísticos e meta-heurísticos amplamente utilizados na literatura para resolução problemas de Otimização Combinatória.


\subsubsection{Heurísticas}

Os métodos heurísticos são utilizados para se encontrar boas soluções para problemas difíceis em um razoável espaço de tempo, mas existem outras razões para se utilizar os métodos heurísticos, dentre eles destacam-se~\cite{marti2011linear}:

\begin{itemize}
   \item Quando nenhum método de resolução do problema em sua otimalidade é conhecido;
   \item Quando, embora exista algum método exato para solução do problema, tal método não pode ser utilizado no ambiente computacional disponível para processamento;
   \item Quando a flexibilidade do método heurístico for fundamental, permitindo, por exemplo, a incorporação de condições que são difíceis de modelar;
   \item Quando o método heurístico for usado como parte de um procedimento global que garanta achar a solução ótima de um problema.
\end{itemize}

Uma boa heurística deve possuir as seguintes propriedades:

\begin{itemize}
   \item Gerar uma solução com um esforço computacional razoável;
   \item Gerar uma solução próxima da solução ótima do problema (com alta probabilidade);
   \item Gerar uma solução muito ruim (longe do ótimo) com baixa probabilidade.
\end{itemize}

Os métodos heurísticos podem ser divididos em sete grandes grupos, que são~\cite{rodrigues:1996}:

\begin{itemize}
  \item \textbf{Heurísticas de construção:} onde se constroem uma solução completa (válida para o problema), a partir de uma solução parcial (incompleta ou nula) através da inserção sucessiva de seus componentes individuais. Geralmente são métodos determinísticos que tendem a se basear na melhor escolha a cada iteração;
  \item \textbf{Heurísticas de melhoria:} essa heurística inicia seu processamento com uma solução válida e vai melhorando essa solução através de sucessivas trocas de elementos. Estas heurísticas também são conhecidas como heurísticas de \textbf{busca local}, onde é realizada uma busca exaustiva na vizinhança da solução inicial até que seja encontrado a melhor solução dessa vizinhança;
  \item \textbf{Heurísticas de decomposição:} o problema original é quebrado em subproblemas simples de se resolver, levando-se em consideração que, de um modo geral, esses subproblemas pertencem a classe de um mesmo problema;
  \item \textbf{Heurísticas de Particionamento:} o problema é dividido em vários problemas menores e, então, as soluções são unidas posteriormente;
  \item \textbf{Heurísticas de relaxação:} o espaço do problema é relaxado com a finalidade de se ter um algoritmo mais rápido e, a solução obtida é então ajustada de maneira que ela se torne factível para o problema original. Relaxar significa retirar algumas restrições do problema;
  \item \textbf{Heurísticas baseadas em formulações matemáticas:} alteram um algoritmo baseado na formulação matemática do problema, objetivando um melhor desempenho no tempo de processamento.
\end{itemize}


\subsubsection{Meta-heurísticas}

Meta-heurísticas são métodos aproximados de resolução de problemas de Otimização Combinatória que fazem uso de mais de um processo heurístico na busca por soluções. São aplicadas em problemas complexos, mal-definidos ou com grande dificuldade computacional, em geral problemas NP-difíceis. Diferentemente das heurísticas, tais métodos conseguem explorar um grande espaço de busca, através de saltos aleatórios no mesmo. As meta-heurísticas servem para três propósitos principais: solucionar problemas de modo rápido, resolver problemas de grande porte, e conter outras heurísticas em seus procedimentos internos. Além disso, eles são simples de criar e implementar, e são muito flexíveis~\cite{Talbi:2009}. As meta-heurísticas também fazem uso da aleatoriedade ou pesquisa estocástica, ao contrário das heurísticas determinísticas. Esta seção baseia-se nas seguintes referências: Rodrigues~\cite{rodrigues:1996}, Talbi~\cite{Talbi:2009} e Luke~\cite{Luke2009Metaheuristics}.


\paragraph{Busca local iterada}\subsubsection*{}\vspace{-1.5cm}

A busca local começa com uma solução inicial. A cada iteração, a heurística substitui a solução corrente por uma solução vizinha cuja função objetivo (FO) é melhor que a solução corrente. A busca termina quando todas soluções vizinhas são piores que a solução corrente, as soluções vizinhas da solução corrente fazem parte de um subconjunto do espaço de soluções. Na Figura~\ref{fig:LS} é apresentado um gráfico com uma curva representando as soluções e uma estratégia de seleção (seleção da solução vizinha).

A busca local pode ser vista como uma busca de melhores soluções em um grafo que representa o espaço de busca. Esse grafo pode ser definido como $G = (S,M)$, onde $S$ representa um conjunto de todas as soluções factíveis do espaço de busca e $M$ representa a relação de vizinhança. No grafo G, uma aresta $(i, j)$ será conectada a qualquer solução vizinha $s_{i}$ e $s_{j}$. Para uma dada solução $s$, o número de arestas associadas será $|N(s)|$ (número de soluções vizinhas).

\begin{figure}[ht]
\centering
\includegraphics[width=.5\textwidth]{./imagens/busca_local.eps}
\caption{Funcionamento do algoritmo de busca local em um determinado espaço de busca.}
\label{fig:LS}
\end{figure}

\subsubsection*{Seleção da melhor solução vizinha}

Muitas estratégias podem ser aplicadas na seleção da melhor solução vizinha (Figura~\ref{fig:Strategy-LS}):

\begin{itemize}
   \item \textbf{Melhor encontrado (\textit{best improvement}):} Nesta estratégia, a melhor solução vizinha (solução que possui o melhor valor de função objetivo) é selecionada. A vizinhança de soluções é avaliada de uma forma totalmente determinística. Por isso, a exploração das soluções vizinhas é exaustiva, todos os possíveis movimentos são utilizados para que seja encontrada a melhor solução. Este tipo de exploração pode consumir bastante tempo para um espaço muito grande de soluções vizinhas;
   \item \textbf{Primeira melhora (\textit{first improvement}):} Esta estratégia consiste em escolher a primeira solução vizinha que é melhor que a solução corrente. Então, a solução corrente é imediatamente substituída por essa solução melhorada. Esta estratégia envolve uma avaliação parcial das soluções vizinhas. Em uma exploração cíclica, as soluções vizinhas são exploradas de modo determinístico seguindo uma dada ordem de geração de soluções. No pior caso (quando nenhuma melhoria é encontrada), uma avaliação completa das soluções vizinhas é realizada;
   \item \textbf{Seleção aleatória (\textit{random selection}):} Nesta estratégia, uma seleção aleatória é aplicada nas soluções vizinhas a fim de melhorar a solução corrente.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.95\textwidth]{./imagens/Estrategia-LS.eps}
\caption{Funcionamento do algoritmo de busca local em um determinado espaço de busca.}
\label{fig:Strategy-LS}
\end{figure}

A qualidade do ótimo local obtido pelo algoritmo de busca local depende de uma solução inicial. Como se pode gerar um ótimo local com tanta variabilidade, a busca local iterada pode ser utilizada para melhorar a qualidade dos sucessivos ótimos locais.

A busca local iterada é baseada no seguinte princípio: Primeiramente, uma busca local é aplicada em uma solução inicial. Assim, a cada iteração, é realizada uma perturbação do ótimo local obtido e, finalmente, uma busca local é aplicada na solução perturbada. A solução gerada é aceita como a nova solução corrente sob determinadas condições. Este processo é repetido durante um determinado número de iterações. O Algoritmo~\ref{code:BuscaLocalIterada} descreve o algoritmo de busca local.

\begin{algorithm}[htpb]
     $s_{*} \longleftarrow $ \textit{BuscaLocal($s_{0}$)} \Comment{Aplica um dado algoritmo de busca local}\;
     \Repita{Critério de parada satisfeito}{
     	  $s' \longleftarrow $ \textit{Perturba($s_{*}$)} \Comment{Perturba a solução corrente}\;
          $s'_{*} \longleftarrow $ \textit{BuscaLocal($s'$)} \Comment{Aplica a busca local na solução perturbada}\;
          $s_{*} \longleftarrow $ \textit{AceitaSolução($s_{*} $ , $ s'_{*}$)} \Comment{Critério de aceitação}\;
     }
     \Retorna{Melhor solução encontrada.}
\caption{Busca local iterada (\textit{Iterated local search}).}
\label{code:BuscaLocalIterada}
\end{algorithm}

Três elementos básicos compõem uma busca local iterada (Figura~\ref{fig:Strategy-ILS}):

\begin{itemize}
   \item \textbf{Busca local:} qualquer meta-heurística (determinística ou estocástica) pode ser utilizada em conjunto com a busca local iterada;
   \item \textbf{Método de perturbação:} a perturbação pode ser vista como um movimento aleatório da solução corrente. A perturbação deve manter alguma parte da solução original e fortemente perturbar a outra parte da solução para que seja possível explorar outras regiões do espaço de busca;
   \item \textbf{Critério de aceitação:} define as condições que o novo ótimo local deve possuir para que ele possa substituir a solução corrente.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/busca_local_iterada.eps}
\caption{Funcionamento do algoritmo de busca local iterada em um determinado espaço de busca.}
\label{fig:Strategy-ILS}
\end{figure}


\paragraph{Algoritmo genético}\subsubsection*{}\vspace{-1.5cm} \label{sec:GA}

Os algoritmos genéticos (GAs) foram originalmente propostos por Holland~\cite{Holland_1975}. Esses algoritmos utilizam o processo de evolução baseado na teoria da evolução de Darwin para resolver problemas, nessa teoria, os indivíduos mais adaptados sobrevivem. Nesse contexto, o termo \textbf{evolução} representa uma solução para o problema (formado por uma cadeia de genes); O termo \textbf{gene} representa uma certa característica da solução representada no cromossomo; O termo \textbf{alelo} representa o valor de gene (usualmente 0 ou 1); A \textbf{função de avaliação (\textit{fitness})} representa o valor associado a um cromossomo para representar quão boa é a solução; A \textbf{população} é o conjunto de possíveis soluções (cromossomos); A \textbf{geração} é a operação para se gerar uma nova população.

Existem muitas implementações de algoritmos genéticos para uma variedade de problemas, os componentes principais de algoritmos genéticos são os seguintes:
\begin{itemize}
  \item \textbf{Solução codificada:} uma representação de cromossomo para as soluções;
  \item \textbf{População inicial:} criação de uma população inicial de cromossomos;
  \item \textbf{Função de avaliação:} medida de avaliação baseada na função objetivo;
  \item \textbf{Seleção:} seleção natural de alguns cromossomos (pais) na população para
        geração de novos membros (filhos) na população;
  \item \textbf{Operações genéticas:} operadores genéticos aplicados aos cromossomos cuja
        regra é criar novos membros (filhos) na população pelo cruzamento de genes de dois
        cromossomos (operações de cruzamento) ou pela modificação de genes de um cromossomo
        (operações de mutação);
  \item \textbf{Substituição:} seleção natural dos membros da população que irão sobreviver;
  \item \textbf{Parâmetro de seleção:} convergência natural de toda população que é
        globalmente melhorada a cada passo do algoritmo.
\end{itemize}

O desempenho do GA depende muito da concepção dos componentes supracitados e da escolha dos parâmetros como o tamanho da população, probabilidades de operações genéticas (taxa de cruzamento e taxa de mutação), e número de gerações.


\subsubsection*{Métodos de seleção}

O mecanismo de seleção é um dos componentes principais dos algoritmos genéticos. O princípio do método de seleção é "quão melhor é um indivíduo, maior será a sua chance de ser um pai".
Através de métodos de seleção, os cromossomos (pais) são selecionados da população para serem combinados e formarem novos cromossomos (filhos), a fim de que sejam aplicadas novas operações genéticas. Dentre os métodos de seleção existentes na literatura, os principais são:

\begin{itemize}
    \item \textbf{Seleção por roleta (\textit{Roulette wheel selection}):} é o método mais comum de seleção, onde é designado a cada indivíduo uma seleção probabilística que é proporcional ao seu valor de avaliação. Seja $f_{i}$ o valor de avaliação baseado na função objetivo de um indivíduo $p_{i}$ na população $P$. A sua probabilidade de ser selecionado é $p_{i} = f_{i}/(\sum_{j=1}^{n} f_{i})$. E seja um gráfico de pizza onde cada indivíduo é posicionado no gráfico de acordo com o seu valor de avaliação. A seleção é realizada através da agulha de uma roleta que é posicionada em volta desse gráfico de pizza. A seleção de $\mu$ indivíduos é realizada através de $\mu$ giros independentes na seleção por roleta, como pode ser observado na Figura~\ref{fig:Selecion-Strategy} (a);
    \item \textbf{Amostragem universal estocástica (\textit{Stochastic universal sampling}):} esse tipo de seleção é semelhante a seleção por roleta, mas para selecionar $\mu$ indivíduos utiliza-se $\mu$ agulhas igualmente posicionadas. Nesta estratégia, em um único giro da roleta são selecionados $\mu$ indivíduos para reprodução, como pode ser observado na Figura~\ref{fig:Selecion-Strategy} (b);
    \item \textbf{Seleção por torneio (\textit{Tournament selection}):} é um método que consiste em sucessivas disputas para realizar a seleção. Primeiramente seleciona-se randomicamente $k$ indivíduos, onde o parâmetro $k$ é o tamanho do grupo do torneio. Um torneio é então aplicado nestes $k$ membros do grupo a fim de selecionar o melhor dentre eles. Para selecionar $\mu$ indivíduos, o procedimento de torneio é realizado $\mu$ vezes.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/roleta.eps}
\caption{(a) seleção por roleta e (b) seleção por amostragem universal estocástica. Adaptado de Talbi~\cite{Talbi:2009}.}
\label{fig:Selecion-Strategy}
\end{figure}

\subsubsection*{Reprodução}

Uma vez que a seleção dos indivíduos é executada, a fase da reprodução conta com a aplicação dos operadores de reprodução, que são:

\begin{itemize}
	\item \textbf{Mutação:} é aplicada em um único indivíduo, a mutação representa pequenas mudanças em indivíduos previamente selecionados na população. A probabilidade $p_{m}$ define a probabilidade de mutação de cada elemento (gene) da solução. Geralmente pequenos valores são recomendados para essa probabilidade ($p_{m} \in [0.001, 0.01]$);
	\item \textbf{Recombinação e cruzamento:} recombina dois ou mais cromossomos para gerar novas soluções.
\end{itemize}


\subsubsection*{Elitismo}

O elitismo consiste em guardar as melhores soluções encontradas durante a busca de soluções. Onde uma população secundária pode ser utilizada para armazenar estas soluções de alta qualidade. O elitismo tem sido utilizado para prevenir a perda de soluções ótimas encontradas durante um processo de busca. Dessa forma, a população secundária não exerce nenhuma influência nas operações de busca da população corrente.


\subsubsection*{Estratégias de substituição}

A fase de substituição diz respeito à seleção dos sobreviventes tanto dos pais como das soluções filhas. Uma vez que o tamanho da população é constante, os indivíduos devem ser retirados de acordo com uma determinada estratégia de seleção, que são:

\begin{itemize}
    \item \textbf{Substituição de gerações (\textit{Generational replacement}):} abrange toda a população de tamanho $\mu$. A população descendente irá substituir sistematicamente a população original;
    \item \textbf{Substituição de regime permanente (\textit{Steady-state replacement}):} A cada geração do algoritmo, somente um descendente é gerado. E, a partir daí, o pior indivíduo da população original é substituído pelo descendente gerado.
\end{itemize}

\pagebreak


\paragraph{Reconexão de caminhos (\textit{path relinking})}\subsubsection*{}\vspace{-1.5cm} \label{secPR}

A técnica de reconexão de caminhos foi originalmente proposta por Glover et al.~\cite{Glover00} para a diversificação do algoritmo de busca dispersa. Esta técnica permite explorar caminhos que ligam duas soluções elite encontradas pela busca dispersa, entretanto, esta estratégia pode ser generalizada e aplicada a outras meta-heurísticas para gerar boas soluções. A ideia principal desta técnica é de gerar e explorar uma trajetória no espaço de busca conectando uma solução inicial $s$ e uma solução guiada ou de destino $s'$. O caminho entre duas soluções no espaço de busca (vizinhança) geralmente resultam em soluções que compartilham atributos comuns das soluções iniciais. O Algoritmo~\ref{code:Path-Relinking} apresenta o esquema de funcionamento do algoritmo de reconexão de caminhos, onde, a cada iteração, o melhor movimento em termos de função objetivo é escolhido e há uma diminuição da distancia $d$ entre duas soluções. Este procedimento é repetido até que a distancia entre as duas soluções seja $0$. A melhor solução encontrada na trajetória é retornada pelo algoritmo.

\begin{algorithm}[htpb]
	 \Entrada{solução inicial $s$ e solução guiada $s'$}
     $x \longleftarrow s$\;
     \Enqto{\textit{dist($x$,$s'$)} $\neq$ $0$}{
          Encontre o melhor movimento $m$ que diminua a \textit{dist($x \oplus m$,$s'$)}\;
          $x \longleftarrow x \oplus m $ \Comment{Aplica o movimento $m$ na solução $x$}\;
     }
     \Retorna{Melhor solução encontrada na trajetória entre $s$ e $s'$}
\caption{Reconexão de caminhos (\textit{path relinking}).}
\label{code:Path-Relinking}
\end{algorithm}

Os principais questionamentos do algoritmo de reconexão de caminhos são~\cite{Talbi:2009}:

\begin{itemize}
    \item \textbf{Seleção do caminho:} o que deve ser considerado na geração do caminho. Uma heurística pode ser utilizada para gerar o caminho que deve ser utilizado para minimizar a distância até a solução guiada. Para isso, uma distância $d$ deve ser definida no espaço de busca associado ao problema. A complexidade computacional para esse procedimento deve ser levada em consideração;
    \item \textbf{Operações intermediárias:} que operações devem ser aplicadas a cada passo da geração do caminho. Algumas soluções selecionadas no caminho podem ser consideradas. Por exemplo, para cada solução intermediária no caminho, um procedimento de busca local pode ser aplicado a fim de melhorar a qualidade da solução.
\end{itemize}

Além disso, para cada par de soluções de $s$ e $s'$, existem várias alternativas diferentes para seleção da solução inicial e solução guiada (Figura~\ref{fig:PR-Strategies}):

\begin{itemize}
   \item \textbf{Caminho avante (\textit{forward}):} a pior solução entre $s$ e $s'$ é utilizada como solução inicial.
   \item \textbf{Caminho reverso (\textit{backward}):} a melhor solução entre $s$ e $s'$ é utilizada como solução inicial. Como a vizinhança da solução inicial é mais explorada do que a vizinhança da solução guiada, a estratégia de caminho reverso é em geral melhor do que a estratégia do caminho adiantado.
   \item \textbf{Reconexão avante-reverso (\textit{back and forward relinking}):} dois caminhos são construídos em paralelo, utilizando alternativamente a solução $s$ como solução inicial e guiada. Apesar desta estratégia apresentar boas soluções, este método adiciona uma sobrecarga no tempo de computação.
   \item \textbf{Reconexão mista (\textit{mixed relinking}):} assim como na estratégia de reconexão avante-reverso, dois caminhos são construídos em paralelo partindo de $s$ até $s'$, mas agora, a solução guiada é uma solução intermediária $m$, que está localizada a uma mesma distância de $s$ e $s'$. Esta estratégia paralela pode reduzir o tempo de execução.
\end{itemize}

\begin{figure}[htpb]
\centering
\includegraphics[width=.7\textwidth]{./imagens/PR-Strategies.eps}
\caption{Diferentes estratégias de reconexão de caminhos em termos das soluções inicial e guiada. Adaptado de Talbi~\cite{Talbi:2009}.}
\label{fig:PR-Strategies}
\end{figure}

\pagebreak

\section{Teoria de escalonamento} \label{ProbEsc}

De acordo com Rodrigues~\cite{rodrigues:2009}, problemas de escalonamento podem ser definidos como sendo a designação ou alocação de determinados recursos a determinadas atividades em função do tempo. Tal alocação sobre o tempo envolve um processo de tomada de decisão que visa otimizar um ou mais critérios de medida de desempenho. Devido ao fato de um dos primeiros problemas modelados como sendo de escalonamento envolver a otimização da produção de uma fábrica, virou consenso definir de maneira geral um problema de escalonamento como sendo a alocação de tarefas a máquinas ou processadores de tal forma a otimizar algum critério de produção. Tais critérios são modelados como uma função matemática de maximização ou minimização chamada de função objetivo.

Existem muitos problemas de escalonamento, variando de acordo com o tempo de processamento, tipos e quantidade de restrições  dos elementos a serem escalonados, condições de execução e critério de otimização, isto é, o número de máquinas pode variar e eles podem ser iguais ou diferentes, os elementos podem ou não ter tempo de início e término bem-definidos, pode haver ou não interrupção nas tarefas (preempção), entre outros.

Nos problemas de escalonamento considerados neste trabalho, o número de tarefas e de máquinas são finitos. O número de tarefas é denotado por $n$ e o número de máquinas é denotado por $m$. Geralmente, $j$ refere-se a uma tarefa enquanto que $i$ refere-se a uma determinada máquina. Se uma tarefa requer uma determinado tipo de processamento ou operação, então o par ($i, j$) refere-se a ao processamento ou operação de uma tarefa $j$ na máquina $i$~\cite{brucker:2006}, \cite{pinedo:2012}. Sejam $m$ as máquinas $M_{j}(j = 1, ..., m)$ que devem processar $n$ tarefas $J_{i}(i = 1, ..., n)$, um escalonamento é para cada tarefa uma alocação de um ou mais intervalos a uma ou mais máquinas. Esta seção baseia-se nas seguintes referências: Rodrigues~\cite{rodrigues:2009}, Brucker~\cite{brucker:2006} e Pinedo~\cite{pinedo:2012}.


\subsection{Representação e notação}

Graham et al.~\cite{Graham_Lawler_Lenstra_Kan_1979} introduziram um esquema de classificação para problemas de escalonamento em termos da notação de três campos  {\boldmath $\alpha | \beta | \gamma$ } onde {\boldmath $ \alpha $} especifica o \textbf{ambiente de processamento} que possui somente uma entrada, {\boldmath $ \beta $} especifica os detalhes das \textbf{características das tarefas} e restrições de escalonamento, pode ter muitas ou nenhuma entrada e {{\boldmath $ \gamma $} especifica a \textbf{função objetivo (FO)} a ser otimizada (\textit{critério de otimização}), geralmente tendo somente uma entrada.

Um escalonamento pode ser representado pelo \textbf{gráfico de Gantt} (Figura~\ref{fig:Gantt-chart-example}), que mostra um exemplo de saída \textbf{orientado-a-máquina} (Figura~\ref{fig:Gantt-chart-example} (a)) onde as tarefas são representadas por caixas retangulares em uma representação do primeiro quadrante do plano cartesiano - o eixo das abcissas representa o tempo de processamento e o eixo das ordenadas representa as máquinas. Outra representação do gráfico de Gantt é a representação \textbf{orientado-a-tarefa} (Figura~\ref{fig:Gantt-chart-example} (b)), onde a diferença é a troca entre as tarefas e máquinas.

\begin{figure}[ht]
\centering
\includegraphics[width=.8\textwidth]{./imagens/Gantt_Chart2.eps}
\caption{Exemplo de representação no gráfico de Gantt: (a) orientado-a-máquina e (b) orientado-a-tarefa~\cite{rodrigues:2009}.}
\label{fig:Gantt-chart-example}
\end{figure}


\subsubsection{Ambiente de processamento}

Os principais ambientes de processamento em um escalonamento e suas notações são definidas a seguir:
\begin{itemize}
 \item \textbf{Ambiente monoprocessado:} quando há um único processador no sistema. A notação utilizada é $1$;

 \item \textbf{Processadores ou máquina paralelas idênticas:} quando existem $m$ máquinas idênticas em paralelo. Utiliza-se a notação $P_{m}$ se o número de processadores é fixo ($m$ é uma constante), e utiliza-se a notação $P$ se o número de processadores é parte da entrada ($m$ é uma variável);

 \item \textbf{Processadores ou máquinas paralelas uniformes:} quando existem $m$ máquinas paralelas com velocidades diferentes. A notação utilizada neste caso é $Q$ e $Q_{m}$;

 \item \textbf{Processadores ou máquinas paralelas não-relacionadas:} quando existem $m$ máquinas em paralelo com desempenhos dependentes da tarefa a ser executada. A notação utilizada neste caso é $R$ e $R_{m}$;

 \item \textbf{Processadores ou máquinas de propósito geral:} quando as $m$ máquinas são divididas em subconjuntos $\mu$, a notação desses subconjuntos é $PMPM$ se as máquinas forem idênticas. Se as máquinas forem paralelas uniformes, a notação é $QMPM$. E, se as máquinas paralelas forem não-relacionadas, a notação é $RMPM$. A notação utilizada para os processadores de propósito geral é $MPM$;

 \item \textbf{\textit{Flow shop}: } quando existe a mesma sequência de máquinas para cada tarefa. Dessa forma, considera-se $m$ máquinas em série, cada tarefa deve ser processada e cada uma dessas $m$ máquinas. Todas as tarefas devem seguir a mesma configuração de processamento, ou seja, elas devem ser processadas primeiramente na máquina $1$, depois na máquina $2$ e assim sucessivamente. Depois de finalizar a sua execução em uma máquina, a tarefa entra na fila para ser executada na próxima máquina. Geralmente, todas as filas são organizadas por ordem de chegada (\textit{First In First Out - FIFO}). A notação utilizada é $F$ e $F_{m}$;

 \item \textbf{\textit{Job shop}: } quando existem máquinas diferentes e em ordem diferente em cada tarefa. A notação utilizada é $J$ e $J_{m}$;

 \item \textbf{\textit{Open shop}: } quando a tarefa é executada em cada máquina exatamente uma vez em cada sequência, esta sequência é diferente para cada tarefa. A notação utilizada é $O$ e $O_{m}$.
\end{itemize}


\subsubsection{Características das tarefas}

Cada \textbf{tarefa (do inglês, \emph{job} ou \emph{task})} pode ter muitas restrições associadas, como as seguintes:
\begin{itemize}
 \item \textbf{Data de chegada ou de disponibilidade (\textit{release date}):} define o momento em que a tarefa pode começar a ser executada. A notação utilizada é $r_{j}$;

 \item \textbf{Data de término sugerida (\textit{due date}):} indica o tempo que a tarefa dever ser finalizada, notação $d_{j}$, sob pena de sofrer alguma penalidade caso ultrapasse tal tempo;

 \item \textbf{Data de término obrigatória (\textit{deadline}):} indica o tempo que cada tarefa deve ser finalizada, notação $D_{j}$, não sendo permitido ultrapassar tal tempo;

 \item \textbf{Tempos de processamento (\textit{processing time}):} restringe o tempo de processamento de cada tarefa, notação $p_{j}$, por exemplo, quando $p_{j} = p$, significa que todas as tarefas possuem o mesmo tempo de processamento, igual a $p$, quando $p_{j} = 1$, significa que todas as tarefas têm o mesmo tempo de processamento igual a 1, mas quando a notação $p_{j}$ é omitida da descrição do problema, as tarefas podem possuir tempos de processamento quaisquer;

 \item \textbf{Peso (\textit{weight}):} que pode representar prioridades iguais ou diferentes. A notação utilizada é $w_{j}$;

 \item \textbf{Preempção (\textit{preemption}):} indica se uma preempção (interrompe e retoma sua execução) é permitida ou não. A notação utilizada é $pmtn$;

 \item \textbf{Sem-espera (\textit{no-wait}):} indica que a tarefa não pode ficar em estado de espera depois de iniciada sua execução. Somente para \textit{flow shops}. A notação utilizada é $nwt$;

 \item \textbf{Restrição no número de tarefas:} restringe o número de tarefas, ou seja, $nbr_{j} = 5$ indica que existem no máximo $5$ tarefas a serem processadas. A notação utilizada é $nbr$;

 \item \textbf{Restrição de precedência (\textit{precedence constraints}):} essas restrições podem aparecer nos ambientes mono e multi-processado, sendo que uma ou mais tarefas devem ser completadas antes que outra tarefa possa começar o seu processamento. Existem casos especiais de restrição de precedência: se cada tarefa tem pelo menos um predecessor e pelo menos um sucessor, as restrições são definidas como \textit{chains}. Se cada tarefa tem pelo menos um sucessor, as restrições são definidas como \textit{intree}. Se cada tarefa tem pelo menos um predecessor as restrições são definidas como \textit{outtree}. A notação utilizada é $prec$;

 \item \textbf{Sequência dependente de tempos de preparação (\textit{sequence dependent setup times}):} onde $s_{jk}$ representa uma sequência dependente de tempos de preparação das tarefas $j$ e $k$, $S_{0k}$ denota o tempo de preparação para a tarefa $k$ se a tarefa $k$ é a primeira na sequência e $s_{j0}$ se a tarefa $j$ é a última da sequência. Se o tempo de preparação entre as tarefas $j$ e $k$ depende da máquina, então o índice $i$ é incluído, ou seja, $s_{ijk}$. Se $s_{jk}$ não aparecer no problema, ou seja, se $s_{jk}$ não aparecer no campo $\beta$, todos os tempos de preparação possuem o valor $0$. A notação utilizada é $s_{jk}$;

 \item \textbf{Processamento em lotes (\textit{batch processing}):} onde uma máquina deve ser capaz de processar um número de tarefas, $b$, simultaneamente, ou seja, pode processar um lote de $b$ tarefas ao mesmo tempo. Os tempos de processamento de todas as tarefas no lote não devem ser os mesmos e o lote todo é finalizado somente quando a última tarefa do lote é completada, implicando que o tempo de processamento de todo o lote é determinado pela tarefa com o maior tempo de processamento. Se $b=1$, então o problema é reduzido ao problema convencional de escalonamento. Outro caso especial é o $b=\infty$, ou seja, não há limite no número de tarefas que a máquina pode processar ao mesmo tempo.

 Utilizam-se as notações $p-batch$, quando o comprimento do lote for igual ao maior dos tempos de processamento dentre todas as tarefas, e a notação $s-batch$, quando o comprimento do lote for igual a soma dos tempos de processamento de todas as tarefas.
\end{itemize}

É chamada \textbf{janela de tempo} (\textit{time window}), um intervalo de tempo determinado por uma data de início e uma data de término. A janela de tempo de uma determinada tarefa, para que seja executada em tempo, é definida por sua data de chegada e por sua data de término sugerida. Uma tarefa pode ser executada em qualquer máquina com mesmo desempenho ou diferentemente em cada máquina, o que pode tomar mais ou menos tempo para ser executada. Neste caso, $p_{ij}$ representa o tempo de processamento que a tarefa $J_{j}$ demora pra ser processada na máquina $M_{i}$. O critério de otimização ou função objetivo $f_{j}(t)$ representa o custo induzido pela tarefa $J_{j}$ quando é executada em um processador até o tempo $t$.


\subsubsection{Critério de otimização}

De acordo com Brucker~\cite{brucker:2006}, existem dois tipos de função de custo, que são: $f_{max}(C) = max\{f_{i}(C_{i})|i = 1,...,n\}$ e $\sum f_{i}(C) = \sum_{i=1}^{n} f_{i}(C_{i})$ chamados de funções objetivo de gargalo (\textit{bottleneck objectives}) ou do tipo MinMax (MaxMin), e funções objetivo de soma total (\textit{sum objectives}), respectivamente. O objetivo é achar um escalonamento factível que minimize uma função de custo obedecendo a certos critérios de otimização. Existem determinadas \textbf{funções objetivos clássicas}, a maioria delas sendo uma \textbf{função regular}, que possui um comportamento não-decrescente em relação aos tempos de completude das tarefas. O tempo de completude da tarefa $j$ na máquina $i$ é denotado por $C_{ij}$. Se a tarefa não for dependente da máquina, o tempo que a tarefa $j$ sai do sistema, ou seja, o tempo que a tarefa finaliza o seu processamento na máquina onde foi processada, é denotado por $C_{j}$.

A seguir serão apresentados exemplo de funções regulares que consideram escalas de tempo, conhecidas como \textbf{critérios proporcionais}, que são~\cite{rodrigues:2009}:

\begin{itemize}
   \item \textbf{Maior tempo de completude (\textit{makespan})} (Notação: $C_{max}$) refere-se ao tempo de completude da última tarefa a terminar sua execução, ou de outra forma, maior tempo de completude dentre todas as tarefas executadas. $C_{max} = max\{C_{1}, ..., C_{m}\}$. Deseja-se minimizar $C_{max}$, pois um \textit{makespan} mínimo geralmente significa uma maior utilização da máquina;

   \item \textbf{Máxima latência (\textit{maximum lateness})} (Notação: $L_{max}$) é definida como $L_{j} = C_{j} - d_{j}$, que será um valor positivo se a tarefa $J_{j}$ for executada com atraso, será um valor negativo se a tarefa for antecipada ou, senão, será um valor nulo. A função de máxima latência ($L_{max}$), então, retorna o valor do maior atraso possível ou menor antecipação se não houver atrasos, considerando todas as tarefas executadas. $L_{max} = max\{L_{1}, ..., L_{n}\}$, onde deseja-se minimizar o $L_{max}$;

   \item \textbf{Tempo total de completude (\textit{total completion time})} (Notação: $\sum C_{j}$ ou $\sum w_{j}C_{j}$) soma de todos os tempos de completude das tarefas (ponderadas ou não), onde deseja-se minimizar $\sum C_{j}$ ou $\sum w_{j}C_{j}$;

   \item \textbf{Tempo total de atraso (\textit{tardiness}) (Notação: $\sum T_{j}$ ou $\sum w_{j} T_{j}$)} trata-se da soma de todos os tempos de atraso das tarefas (ponderadas ou não). Dessa forma, o atraso assume um valor positivo se as tarefas forem atrasadas, caso contrário, o atraso assume o valor $0$. Sendo $T_{j} = max\{L_{j},0\}$, onde deseja-se minimizar $\sum T_{j}$ ou $\sum w_{j} T_{j}$.
\end{itemize}

Também existem funções objetivo que não dependem diretamente do tempo, sendo conhecidos como \textbf{critérios permanentes}, que são:

\begin{itemize}
   \item \textbf{Número de tarefas tardias} (Notação: $\sum U_{j}$ ou $\sum w_{j} U_{j}$) é o número total de tarefas executadas com atraso (ponderadas ou não), onde $U_{j}$ é uma penalidade unitária caso a tarefa esteja atrasada (e nula caso contrário), como no exemplo a seguir:

   \begin{equation} U_{j} = \left \lbrace \begin{array}{l} 1 \text{ se } C_{j} > d_{j} \\ 0 \text{ caso contrário} \\ \end{array} \right .\end{equation}

\end{itemize}

A função objetivo que envolve a minimização de atraso pertence a classe de funções objetivo que possui medidas \textbf{regulares} de desempenho. Uma função objetivo possui uma medida de desempenho regular quando é não-decrescente em $C_{1}, ..., C_{n}$. Pesquisas recentes consideram cada vez mais o estudo de funções objetivo que são \textbf{não-regulares}, como por exemplo, a que representa penalidades de antecipação (ponderadas ou não). A antecipação assume um valor positivo se as tarefas forem antecipadas, caso contrário, o valor de antecipação assume o valor $0$. Desta forma, a penalidade de antecipação é não-crescente em $C_{j}$ e pode ser formalmente descrita como segue:

\begin{itemize}
   \item \textbf{Tempo total de antecipação (\textit{earliness}) (Notação: $\sum E_{j}$ ou $\sum w_{j} E_{j}$)} trata-se da soma de todos os tempos de antecipação das tarefas (ponderadas ou não). Desta forma, a antecipação assume um valor positivo se as tarefas forem antecipadas, caso contrário, o valor de antecipação é valor $0$. Sendo $E_{j} = max{d_{j} - C_{j}, 0}$, onde deseja-se minimizar $\sum E_{j}$ ou $\sum w_{j} E_{j}$.
\end{itemize}

Para atender ao conceito surgido nas indústrias de produção sem folga, ou seja, de produto produzido o mais próximo possível da data de entrega (do inglês \emph{Just-in-Time} - JIT), aplica-se uma combinação dos critérios de antecipação e atraso anteriormente descritos, e, desta forma, a função objetivo consiste na soma das tarefas escalonadas com antecipação e atraso, ponderadas ou não, tal como segue:

\begin{equation}
   \sum_{j=1}^{n}{\alpha_{j} E_{j}} + \sum_{j=1}^{n}{\beta_{j} T_{j}}.
\end{equation}

\noindent Observa-se que na formulação acima, as tarefas são ponderadas e o peso associado à antecipação da tarefa $j$ ($\alpha_{j}$) difere do peso associado ao atraso da tarefa $j$ ($\beta_{j}$). Se os pesos forem iguais para ambas penalidades considerando a mesma tarefa, então, basta isolar a constante do somatório.

Um exemplo para o escalonamento com penalidades de antecipação e atraso em ambiente de máquinas paralelas idênticas é apresentado na Figura~\ref{fig:Gantt} onde, na Figura~\ref{fig:Gantt} (a) é apresentado um exemplo de instância com $6$ tarefas para o problema com seus respectivos valores para tempos de processamento ($p_{j}$), data de término sugerida ($d_{j}$), penalidades de antecipação ($\alpha_{j}$), penalidades de atraso ($\beta_{j}$), tempo de completude ($C_{j}$) das tarefas, valores de antecipação ($E_{j}$) e atraso ($T_{j}$) das tarefas, e os valores da antecipação ponderada ($\alpha_{j} E_{j}$) e do atraso ponderado das tarefas ($\beta_{j} T_{j}$) e na Figura~\ref{fig:Gantt} (b) pode-se observar como fica a representação do escalonamento em três máquinas para essa instância. O valor de antecipação é obtido pela diferença entre data de término sugerida e o tempo de completude, e o valor de atraso é obtido através de diferença entre o tempo de completude da tarefa e a data de término sugerida, caso o resultado de uma dessas diferenças seja negativo, é atribuído o valor $0$ no lugar do resultado negativo. Ao final, o peso ou penalidade de cada tarefa é multiplicado com o seu respectivo valor de antecipação ($E_{j}$) ou atraso ($T_{j}$) e, depois esses resultados são somados obtendo assim o valor total de antecipação ponderada e de atraso ponderado das tarefas.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./imagens/GanttChart.eps}
\caption{(a) Exemplo de uma instância de $6$ tarefas para o problema de escalonamento com antecipação e atraso (b) representação do escalonamento através do gráfico de Gantt orientado-a-máquina.}
\label{fig:Gantt}
\end{figure}


\subsection{Hierarquia de complexidade}

Os problemas de escalonamento de tarefas são problemas de \textbf{otimização combinatória}. Existem inúmeros problemas de escalonamento, classificados em diferentes classes de \textbf{complexidade computacional}. Tal complexidade determina a natureza do algoritmo a ser desenvolvido e, muitas vezes, um algoritmo para um determinado problema de escalonamento pode ser aplicado para a solução de outro problema, pois muitos desses problemas tratam-se de casos particulares ou generalizações de outros. Por exemplo, o problema $1||\sum C_{j}$ é um caso especial do problema $1||\sum w_{j} C_{j}$, dessa forma, um algoritmo para $1|| \sum w_{j} C_{j}$ pode também ser utilizado para solucionar o problema $1||\sum C_{j}$. Na terminologia de complexidade é dito que o problema $1||\sum C_{j}$ é redutível ao problema $1||\sum w_{j} C_{j}$. Que é denotado por suas \textbf{hierarquias de complexidade}~\cite{pinedo:2012},\cite{rodrigues:2009},\cite{brucker:2006}:

\begin{equation}
    1||\sum C_{j} \propto 1||\sum w_{j} C_{j}.
\end{equation}

%\noindent Baseado neste conceito, uma série de reduções pode ser estabelecida. Por exemplo,

%\begin{equation}
 %    1||\sum C{j} \propto 1||\sum w_{j} C_{j} \propto P_{m}||\sum w_{j} C_{j} \propto Q_{m}|prec|\sum w_{j} C_{j}.
%\end{equation}

\noindent Entretanto, também podem existir muitos problemas que não são comparáveis uns com os outros. Por exemplo, $P_{m}||\sum w_{j} T_{j}$ não é comparável com o problema $J_{m} || C_{max}$.

%Em comparação com as diferentes complexidades de problemas de escalonamento, é interesse saber como uma pequena mudança no problema pode afetar a sua complexidade.

Na Figura~\ref{fig:Sched-complexity} (a) são apresentadas as reduções elementares para os principais ambientes de processamento; na Figura~\ref{fig:Sched-complexity} (b) são apresentados os diagramas de inclusão para algumas restrições de processamento; e na Figura~\ref{fig:Sched-complexity} (c) são apresentadas as reduções elementares para as funções objetivo.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./imagens/Sched-Complexity.eps}
\caption{Hierarquias de complexidade dos problemas de escalonamento determinísticos: (a) relação de complexidade entre os ambientes de processamento (b) relação entre as principais características das tarefas em um escalonamento (c) relação de complexidade entre as funções objetivo clássicas (d) relação de complexidade entre as funções objetivo com antecipação e atraso.}
\label{fig:Sched-complexity}
\end{figure}

\pagebreak

\section{Considerações finais}

Este capítulo apresentou a fundamentação teórica necessária para a resolução de problemas de otimização combinatória, incluindo métodos exatos e aproximados. Na teoria de escalonamento foram resumidos os principais conceitos, classificações, notações e políticas de escalonamento. O estudo destes conceitos foram de extrema importância para o desenvolvimento deste trabalho.