\chapter{Fundamentos teóricos} \label{chap-FT}

Para a realização da pesquisa aprofundada envolvendo problemas de escalonamento de tarefas com penalidades de antecipação e atraso, sua conceituação e modelagem teórica, bem como o desenvolvimento de métodos de resolução apropriados, a fundamentação teórica necessária envolve o estudo da área de Otimização Combinatória, com ênfase em modelagem matemática e métodos de resolução, bem como o estudo de Teoria de Escalonamento.

Neste capítulo, portanto, são apresentados os conceitos e os principais problemas de Otimização Combinatória, incluindo seus principais métodos de resolução, exatos e aproximados. A Teoria de Escalonamento, que se propõe a conceituar, classificar e apresentar modelos teóricos, notação, políticas de escalonamento e outras propriedades para obtenção de escalonamentos ótimos, é também resumida neste capítulo. As seções seguintes abordam os tópicos citados acima.



\section{Otimização Combinatória}

Otimização Combinatória é uma área de pesquisa que trata um tipo especial de problema de otimização matemática cujo conjunto de soluções factíveis pode ser representado por um espaço de busca discreto, onde se deseja encontrar, dentre todas as possíveis soluções, aquela solução (ou soluções) cujo custo maximize ou minimize uma determinada função objetivo (ou múltiplos objetivos), respeitando um determinado conjunto de restrições~\cite{marti2011linear} \cite{rodrigues:1996}. Dependendo da complexidade do problema, uma forma de solucionar seria simplesmente enumerar todas as soluções possíveis e retornar a melhor delas. Entretanto, para problemas com um espaço de busca exponencial, este método torna-se impraticável, o que desperta cada vez mais a atenção de pesquisadores da área em propor modelos teóricos mais robustos e métodos mais eficientes, a fim de obter melhores resultados em tempo de execução adequado.

Os problemas de Otimização Combinatória surgem nos mais diversos contextos e, certamente, em todas as áreas tecnológicas, de logística e de gestão industrial~\cite{Lawler:2001}. Um grande número de problemas de otimização combinatória ocorre em projetos de sistemas de distribuição e alocação de recursos, projetos de redes de computadores, roteamento de veículos, escalonamento de tarefas em máquinas, empacotamento de caixas em contêineres, cortes em placas ou madeira, sequenciamento de genes e DNA, modelagem molecular, localização e alocação de canais em redes de sensores sem fio e assim sucessivamente. Estes problemas exigem, cada vez mais, novas abordagens e métodos, envolvendo novas ideias teóricas, matemático-computacionais, para serem solucionados de maneira eficiente.

Os problemas de otimização combinatória podem ser classificados da seguinte maneira~\cite{MullerMerbach:1981}:

\begin{itemize}
  \item \textbf{problemas de atribuição:} onde dois ou mais conjuntos estão disponíveis e o problema consiste em encontrar as \textit{n-uplas} que satisfaçam as restrições. Exemplo: coloração em grafos, problema do fluxo máximo em redes e problemas de escalonamento;
  \item \textbf{problemas de sequenciamento:} onde um conjunto discreto está disponível para ser ordenado sequencialmente de modo que sejam satisfeitas as restrições do problema. Exemplo: problema do caixeiro viajante e problema do caminho mínimo;
  \item \textbf{problemas de seleção:} onde a solução é formada a partir de um conjunto discreto de objetos de modo que sejam satisfeitas as restrições do problema. Exemplo: problema da mochila e árvore de espalhamento mínimo;
  \item \textbf{problemas de composição:} são problemas que são compostos por características de duas ou três classes simultaneamente. Exemplo: problema da mochila e árvore de espalhamento mínimo.
\end{itemize}


Os problemas de otimização combinatória podem ser classificados quanto à complexidade, o que permite a separação dos problemas fáceis dos difíceis. Todos os problemas de otimização combinatória possuem uma versão de decisão, onde suas soluções consistem em uma resposta positiva (sim) ou negativa (não) para um determinado questionamento quanto a existência de alguma solução. Estes problemas podem ser classificados de acordo com a \textbf{Teoria da NP-Completude}, onde o problema é tratado como um conjunto de parâmetros (definição das instâncias) e um conjunto do propriedades (restrições do problema). Para as instâncias de um mesmo problema, as únicas variações estão nos conjuntos de parâmetros. A teoria da complexidade considera o tamanho das instâncias como sendo a quantidade de \textit{bits} necessária para representá-las em computadores digitais~\cite{GareyJohnson:1979}.



De acordo com as suas classes de complexidade, os problemas de otimização combinatória podem ser classificados em três grandes classes (Figura~\ref{fig:NP-Complete}):

\begin{itemize}
   \item \textbf{P (\textit{Polinomial time}):} são problemas cujo esforço computacional de pelo menos um algoritmo conhecido cresce polinomialmente em função do tamanho da instância. Um exemplo de problemas que possuem algoritmos eficientes são: ordenação, árvore de emparelhamento mínimo e fluxo em redes;
   \item \textbf{NP (\textit{Non-deterministic Polinomial time}):} são problemas onde o esforço computacional do melhor algoritmo conhecido cresce exponencialmente em função do tamanho da instância, onde não se sabe da existência de algoritmos melhores e dada uma instância para o problema, pode-se verificar em tempo polinomial se a solução satisfaz a versão de decisão do problema de modo positivo ou negativo;
   \item \textbf{EXPTIME:} são semelhantes aos problemas da classe NP, mais nesse caso, existe a garantia da não existência de algoritmos melhores do aqueles de tempo exponencial. Como o problema da Torre de Hanói, por exemplo.
\end{itemize}

Existe toda uma hierarquia de classes de complexidade computacional correlacionando estas três classes acima com outras, tanto em relação ao tempo quanto ao espaço (PSPACE, EXPSPACE, etc) necessários para um algoritmo resolver na otimalidade e considerando o pior caso possível um problema da classe, segundo o modelo téorico determinístico de máquina de Turing. Entretanto, nesta revisão apenas as classes mais clássicas e básicas estão sendo consideradas. Assim, além das classes citadas acima, existem duas outras classes que contém diversos problemas importantes e difíceis computacionalmente de serem tratados (Figura~\ref{fig:NP-Complete}), que são:

\begin{itemize}
   \item \textbf{NP-Difíceis:} são os problemas "pelo menos tão difíceis quanto os problemas mais difíceis em NP", e que para os quais só são conhecidos algoritmos de tempo exponencial de execução;
   \item \textbf{NP-Completos:} são todos os problemas da classe NP que são NP-Difíceis. Dessa forma, se algum problema NP-Completo pertencer a classe P, então P = NP. Vários problemas foram provados como sendo da classe NP-Completos, como: problema da cobertura de vértices, coloração de vértices em grafos e ciclo hamiltoniano. Estes problemas puderam ser identificados através do Teorema de Cook, que estabelece que todos os problemas da classe NP são polinomialmente redutíveis ao Problema da Satisfabilidade (\textit{SAT Problem});
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./imagens/NP-Complete.pdf}
\caption{Relação entre as principais classes de problemas segundo a complexidade computacional - P, NP, NP-Difíceis e NP-Completos -, segundo o famoso problema em aberto P=NP?.}
\label{fig:NP-Complete}
\end{figure}

Nas próximas subseções, serão detalhados os métodos de resolução de problemas de Otimização Combinatória, sendo divididos em exatos (Subseção \ref{subsec:ME}) e aproximados (Subseção \ref{subsec:MA}). Métodos exatos são todos aqueles que devolvem a melhor solução possível - solução ótima - para o problema que está sendo resolvido. Métodos aproximados são aqueles que, de modo geral, devolvem uma solução válida para o problema sem a garantia de que seja a melhor solução possível e, neste caso, podem ser determinísticos (maioria das heurísticas simples) ou estocásticos (meta-heurísticas e outros métodos que fazem uso de aleatoriedade e processos estocásticos). Dentre os métodos aproximados, existem também os chamados algoritmos aproximativos, que são métodos aproximados que devolvem uma solução aproximada cuja razão de aproximação da solução ótima é conhecida.



\subsection{Métodos exatos} \label{subsec:ME}

Os métodos exatos possuem a característica de fornecerem sempre a solução ótima para um problema de Otimização Combinatória, dada a especificação do problema expressa através de um modelo teórico. Geram sempre a melhor solução possível, mas, se o problema for NP-difícil, não garantem a resolução em um tempo computacional adequado, sendo de tempo exponencial no geral. O método mais intuitivo seria um método de \textbf{enumeração explícita} (de \textbf{busca exaustiva} ou, popularmente chamado de \textbf{força bruta}), que consiste em enumerar explicitamente todas as possibilidades de solução do problema e, então, escolher a melhor solução encontrada. Mas, a busca exaustiva é computacionalmente inviável para os problemas de Otimização Combinatória NP-difíceis. Desta forma, na tentativa de tornar o processo algorítmico menos custoso,  métodos de enumeração implícita são utilizados, consistindo em usar modelos teóricos mais robustos e estratégias algorítmicas mais sofisticadas para uma resolução mais rápida do problema, gerando-se a solução ótima, mas sem ter o custo de se gerar todas as soluções explicitamente. Dentre tais métodos de enumeração explícita, os mais clássicos e aplicados são: Programação Dinâmica, Branch-and-Bound, métodos de corte e de geração de colunas, Branch-and-Cut, Branch-and-Price e combinações entre os mesmos. Nas subseções seguintes tais métodos são brevemente descritos.


\subsubsection{Programação Dinâmica}

Programação Dinâmica (PD) é um método de enumeração implícita que envolve uma sequência de decisões inter-relacionadas na resolução do problema. Trata-se de um
esquema de enumeração de soluções que visa, através de uma abordagem de divisão e conquista (decomposição), minimizar o montante de computação a ser feito. Este método é geralmente aplicado quando há casos em que um mesmo subproblema aparece diversas vezes ao longo do processo, onde a decomposição pura simples é incapaz de reconhecer este fato. Através da PD, é possível resolver um subproblema uma vez e reutilizar essa solução toda vez que o mesmo subproblema aparecer novamente. Este método pode ser aplicado tanto para problemas que possuem solução polinomial quanto para problemas cujo melhor algoritmo conhecido possui complexidade de tempo exponencial.

Os aspectos básicos que caracterizam problemas de PD são apresentados a seguir~\cite{Loesch2009}:

\begin{itemize}
   \item o problema pode ser dividido em \textbf{estágios}, também chamados de etapas, onde a cada estágio deve-se estabelecer uma \textbf{decisão política}, ou seja, é aquela decisão que quando tomada em um determinado estágio relaciona-se com os estágios posteriores. Esta estratégia começa pelos problemas menores a problemas cada vez maiores, até que o problema original seja resolvido, \textbf{estratégia \textit{bottom-up}};
   \item cada estágio ou etapa tem um conjunto de \textbf{estados} associados a ele. Esses estados podem representar várias condições possíveis, que são os estágios do problema, dentro dos quais um determinado sistema pode estar inserido. Esse conjunto de estados pode ser finito ou infinito;
   \item o efeito da \textbf{decisão política} é transformar o estado do estágio atual em um estado do próximo estágio. Quando o estado do próximo estágio admite apenas uma interpretação (determinada pela decisão política), trata-se de um problema de PD determinística. Pode ocorrer que o estado destino dependa também de alguma distribuição probabilística, neste caso, tem-se um problema de PD probabilístico;
   \item "dado o estado atual, uma política ótima para os estágios restantes é independente da política adotada nos estágios anteriores". Esta propriedade é chamada de \textbf{princípio da condição de ótimo}, ou princípio da \textbf{otimalidade de Bellman}.
\end{itemize}

Não existe uma formulação matemática padrão para resolver toda a categoria de problemas de PD. A PD modela o problema \textbf{recursivamente}, essa modelagem pode ser definida por uma \textbf{relação de recorrência} que representa a solução do problema, mas o problema é resolvido iterativamente. É utilizada uma tabela auxiliar que contém um entrada para cada subproblema distinto, de modo que se esse subproblema ocorrer novamente a solução já calculada desse subproblema é extraída da tabela em tempo constante.


\subsubsection{\textit{Branch-and-Bound}}

O método \textit{Branch-and-Bound} também adota uma estratégia de \textbf{enumeração implícita} para a resolução de problemas de Otimização Combinatória. A ideia básica consiste em um particionamento inteligente do espaço de busca (que pode ser representado por uma árvore), descartando partes que não poderão mais fornecer nenhuma solução ótima para o problema~\cite{Papadimitriou:1982}. A divisão do problema corresponde ao processo de enumerar as possibilidades válidas ou simplesmente ramificação  (do inglês, \textit{branching}), combinada com o processo de verificação do valor da função objetivo que se baseia em limites inferiores e superiores para o problema (do inglês, \textit{bounding}), e que deste modo, pode desconsiderar a ramificação por subárvores que matematicamente não produzirão valores melhores do que os já obtidos.

Dessa forma, seja um problema de minimização $P$. Os subproblemas de $P$ são os subconjuntos $S'$ do conjunto $S$ de soluções viáveis de $P$. Sendo assim, a partir do problema original $P$, pode-se estabelecer um limite inferior para o problema desconsiderando-se a restrição de integralidade e, então, o problema relaxado (relaxação linear) é resolvido com um método de solução de programação linear contínua, como o Simplex. Se a solução obtida for inteira (todas as variáveis de decisão forem inteiras na solução do Simplex), então, considera-se o problema resolvido. Caso contrário, consideram-se os seguintes passos~\cite{brucker:2006}:

\begin{itemize}
   \item \textbf{ramificação (\textit{branching:})} $S$ é substituído por problemas menores $S_{i}(i = 1, ..., n)$. Este processo é chamado de \textbf{ramificação} (\textit{branching}), que trata-se de um processo recursivo, ou seja, $S_{i}$ é a base de outra ramificação. Todo o processo é representado por uma \textbf{árvore de ramificações} (\textit{branching tree}), onde $S$ é a raiz da árvore de ramificação e $S_{i}(i = 1, ..., n)$ são os filhos de $S$. Os ramos da árvore recebem restrições incorporadas pelo processo de ramificação, sobre uma variável de decisão $x_{i}$ (ramificações com restrições $x_{i} \le n$ e $x_{i} \ge n + 1$, por exemplo), esses ramos são chamados de \textbf{subproblemas} (Figura~\ref{fig:BB});
   \item \textbf{definição dos limites (\textit{boundings}):} no processo de ramificação pode-se chegar nas seguintes situações nos subproblemas:
        \begin{enumerate}
            \item \textbf{a restrição adicionada torna o problema inviável:} assim a há mais ramificação a partir deste nó (o nó é \textbf{podado});
            \item \textbf{a solução do nó é inteira:} não haverá mais ramificação a partir deste nó e a solução deste nó será a melhor solução inteira atual, onde, a partir daí, é analisado se esta for a primeira melhor solução inteira, ela passará a ser um \textbf{limite superior} do problema original de minimização (ou inferior se for de maximização), ou seja, se as próximas soluções encontradas forem maiores que esta, não haverá ramificação (também serão podados). Se já houver um limite superior e se a nova solução obtida for menor que o limite superior armazenado, a nova solução passará a ser o novo limite superior do problema de minimização $P$.
        \end{enumerate}
   \item Quando não for mais possível ramificar, o último limite superior armazenado é a solução ótima do problema de programação inteira.
\end{itemize}

O \textit{Branch-and-Bound} termina quando todos os subproblemas tiverem sido resolvidos. A escolha de bons algoritmos para o cálculo dos limites inferiores e superiores é crucial, justamente para que se possa eliminar uma grande parte do conjunto de soluções factíveis sem precisar enumerá-las~\cite{rodrigues:1996}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{./imagens/BB.eps}
\caption{Ramificação da árvore de \textit{Branch-and-Bound} para um conjunto de soluções $S$.}
\label{fig:BB}
\end{figure}


\subsubsection{Cortes no plano}

Um plano de corte define uma restrição a mais para o problema, eliminando assim pontos extremos contínuos, sem remover nenhum ponto inteiro factível. Algoritmos de cortes no plano (\textit{cutting plane algorithms}) iniciam  seu processamento através de uma relaxação linear do problema e a partir daí, novas desigualdades (cortes no plano) vão sendo adicionadas ao problema relaxado. O objetivo é colocar a solução ótima do problema de programação inteira como um vértice do politopo, de forma que um método de solução, como o Simplex, possa encontrar e retornar a solução.

A partir de uma solução contínua da relaxação do problema, pode-se utilizar esses dados para criar uma nova restrição que corta pontos contínuos do politopo. Este processo de adicionar cortes que não excluam pontos inteiros viáveis do problema é ilustrado na Figura~\ref{fig:Cutting-planes}~\cite{Papadimitriou:1982}. A Figura~\ref{fig:Cutting-planes} (a) apresenta o problema de programação inteira e a solução ótima contínua $x^{*}$. Uma restrição linear, corte no plano (ou simplesmente corte), é adicionado na Figura~\ref{fig:Cutting-planes} (b), modificando assim o conjunto de soluções viáveis do problema (sem a perda de pontos inteiros) e o novo ótimo contínuo é movido de lugar. A Figura~\ref{fig:Cutting-planes} (c) apresenta o resultado após a adição de outro plano de corte, o efeito agora é fazer o ótimo contínuo virar uma solução inteira para o problema.

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/Cutting-planes.eps}
\caption{Ilustração do algoritmo de cortes no plano: (a) solução ótima contínua $x^{*}$. (b) nova solução ótima contínua $x^{*}$ após um corte. (c) solução do problema de programação inteira após dois cortes~\cite{Papadimitriou:1982}.}
\label{fig:Cutting-planes}
\end{figure}

A inequação adicionada no problema relaxado é chamada de \textbf{Cortes de Gomory}. A aplicação repetida destes cortes no problema relaxado garante chegar no ponto ótimo do problema, conforme mostrado na Figura~\ref{fig:Cutting-planes}.


\subsubsection{\textit{Branch-and-Cut}}

O método \textit{Branch-and-Cut} (B$\&$C) é um método exato de programação linear inteira, proposto por Padberg e Rinaldi~\cite{Padberg:1987} e aplicado inicialmente para solucionar o problema do caixeiro viajante. Este algoritmo trata-se de uma combinação dos algoritmos \textit{Branch-and-Bound} com planos de corte. Apesar de ambos serem capazes de solucionar um problema de programação linear inteira, eles levam um certo tempo para encontrar uma solução ótima. Dessa forma, através da combinação dos dois métodos é possível diminuir esse tempo. A cada nó da árvore, busca-se o máximo de cortes que podem ser inseridos em um tempo razoável, reduzindo assim o limite superior do nó e, consequentemente, reduzindo também o tamanho da árvore de \textit{Branch-and-Bound}, onde os cortes podem ser controlados por algum critério, tais como:

\begin{itemize}
   \item realizar $n$ cortes de Gomory a cada nó;
   \item adicionar inequações específicas do problema original;
   \item efetuar cortes a cada nível da árvore que seja múltiplo de algum valor.
\end{itemize}

No \textit{Branch-and-Cut} também consideram-se os cortes nos estágios de enumeração da árvore de pesquisa. Assim, através desta abordagem, é possível que se guarde uma restrição necessária para um nó de uma determinada sub-árvore, de modo elas sejam válidas para os nós de outras sub-árvores da árvore de pesquisa. O procedimento é iniciado com a relaxação do problema de programação inteira, então o problema relaxado é resolvido e se a solução violar as restrições de integralidade do problema original, o corte é aplicado (adiciona-se mais uma restrição). O objetivo é achar a solução ótima do problema sem que todas as restrições do problema original sejam adicionadas no problema relaxado.

Também existem técnicas de pré-processamento, onde tenta-se melhorar a relaxação linear através de considerações algébricas, onde variáveis e restrições são checadas para evitar redundância, alguns coeficientes de restrições são ajustados e algumas variáveis são fixadas a certos valores, sem que isto afete o valor da solução ótima do problema. Assim, é possível reduzir o número de variáveis significativamente, tornando o problema mais fácil de se resolver. Métodos heurísticos podem ser aplicados a fim de que se obtenha boas soluções, em um curto espaço de tempo, e assim reduzir o tamanho da árvore de busca do \textit{Branch-and-Cut}~\cite{rodrigues:1996}.

\subsubsection{\textit{Branch-and-Price}}

O método \textit{Branch-and-Price} (B$\&$P) é uma composição do método \emph{Branch-and-Bound} com métodos de geração de colunas, muito adequado para problemas de programação inteira muito grandes, que possui um número muito grande de variáveis. Difere do método \emph{Branch-and-Cut}, que 'gera linhas', ou seja, relaxa o problema e depois adiciona as restrições relaxadas (linhas da formulação matemática), com o intuito de não precisar adicionar tudo e, sim, em uma ordem interessante para encontrar rapidamente a melhor solução inteira para o problema. O \textit{Branch-and-Price}, por sua vez, 'gera colunas', ou seja, relaxa o problema desconsiderando variáveis - colunas da formulação matemática, para depois adicioná-las de maneira a não precisar adicionar todas de volta e mesmo assim encontrar a melhor solução inteira para o problema.

O B$\&$P é usado em conjunto com o algoritmo \textit{Branch-and-Bound}, começando o seu processamento através da relaxação linear do problema de programação inteira, onde, baseando nas linhas e colunas dadas pelo seu modelo matemático (linhas são as restrições e colunas representam os valores das variáveis em cada restrição), muitas colunas são deixadas de fora. Esta formulação é chamada de \textbf{problema mestre restrito}, cuja solução ótima da relaxação linear é obtida se todas as colunas da relaxação possuírem colunas com custo reduzido positivo (se for um problema de minimização), mas como o problema mestre restrito não contém todas as colunas da relaxação linear do problema, não dá para saber se a solução é ótima. Dessa forma, um \textbf{subproblema gerador de colunas} é utilizado para verificar se a solução é ótima, identificando colunas com um custo reduzido negativo. Se a solução não for ótima, o subproblema gerador de colunas seleciona ao menos uma coluna com custo reduzido negativo. Caso tenha esta coluna, ela é então adicionada ao problema mestre restrito e o procedimento pára quando não mais identificadas colunas com custo reduzido negativo. Assim, a solução ótima para o problema mestre restrito é também a solução ótima da relaxação linear.

Pode ser que a solução ótima da relação linear não seja inteira. Assim, é necessário que seja utilizada uma estratégia de ramificação para que soluções viáveis do problema de programação inteira sejam encontradas. Esta estratégia de ramificação do \textit{Branch-and-Price} deve restringir o problema mestre restrito, sem modificar a estrutura do problema original, permitindo que o subproblema gerador de colunas permaneça o mesmo para os outros nós da enumeração. A cada ramificação de nós, um problema mestre restrito é criado e a relaxação destes nós é solucionada novamente por geração de colunas. Este processo é repetido enquanto a solução ótima das novas relaxações forem fracionárias. Um nó pára de ser explorado quando possui uma solução inteira ou quando valor da função objetivo da relaxação linear neste nó é maior que o valor do limite superior (se o problema for de minimização)~\cite{Ribeiro:2009}.



\subsection{Métodos Aproximados} \label{subsec:MA}

Os métodos aproximados para resolução de problemas de Otimização Combinatória, ao contrário dos métodos exatos, não garantem a obtenção de uma solução ótima para o problema, mas tentam gerar uma boa solução para o problema (podenso até ser a ótima) em um tempo computacional relativamente bem menor do que os métodos exatos. Esta característica, de gerar boas soluções viáveis rapidamente, e sem precisar manipular modelos teóricos complicados, faz com que tais métodos sejam muito utilizados na resolução de problemas de Otimização Combinatória, principalmente em grandes aplicações reais.

Nas próximas subseções são abordados os principais métodos heurísticos e meta-heurísticos amplamente utilizados na literatura para resolução problemas de Otimização Combinatória.


\subsubsection{Heurísticas}

Os métodos heurísticos são utilizados para se encontrar boas soluções para problemas difíceis em um razoável espaço de tempo, mas existem outras razões para se utilizar os métodos heurísticos, dentre eles destacam-se~\cite{marti2011linear}:

\begin{itemize}
   \item Quando nenhum método de resolução do problema em sua otimalidade é conhecido;
   \item Quando, embora exista algum método exato para solução do problema, tal método não pode ser utilizado no ambiente computacional disponível para processamento;
   \item Quando a flexibelidade do método heurístico for fundamental, permitindo, por exemplo, a incorporação de condições que são difíceis de modelar;
   \item Quando o método heurístico for usado como parte de um procedimento global que garanta achar a solução ótima de um problema.
\end{itemize}

Uma boa heurística deve possuir as seguintes propriedades:

\begin{itemize}
   \item Gerar uma solução com um esforço computacional razoável;
   \item Gerar uma solução próxima da solução ótima do problema (com alta probabilidade);
   \item Gerar uma solução muito ruim (longe do ótimo) com baixa probabilidade.
\end{itemize}

Os métodos heurísticos podem ser divididos em sete grandes grupos, que são~\cite{rodrigues:1996}:

\begin{itemize}
  \item \textbf{heurísticas de Construção:} onde se constroem uma solução completa (válida para o problema), a partir de uma solução parcial (incompleta ou nula) através da inserção sucessiva de seus componentes individuais. Geralmente são métodos determinísticos que tendem a se basear na melhor escolha a cada iteração;
  \item \textbf{heurísticas de melhoria:} essa heurística inicia seu processamento com uma solução válida e vai melhorando essa solução através de sucessivas trocas de elementos. Estas heurísticas também são conhecidas como heurísticas de \textbf{busca local}, onde é realizada uma busca exaustiva na vizinhança da solução inicial até que seja encontrado a melhor solução dessa vizinhança;
  \item \textbf{heurísticas de decomposição:} o problema original é quebrado em subproblemas simples de se resolver, levando-se em consideração que, de um modo geral, esses subproblemas pertencem a classe de um mesmo problema;
  \item \textbf{heurísticas de particionamento:} o problema é dividido em vários problemas menores e, então, as soluções são unidas posteriormente;
  \item \textbf{heurísticas de relaxação:} o espaço do problema é relaxado com a finalidade de se ter um algoritmo mais rápido e, a solução obtida é então ajustada de maneira que ela se torne factível para o problema original. Relaxar significa retirar algumas restrições do problema;
  \item \textbf{heurísticas baseadas em formulações matemáticas:} alteram um algoritmo baseado na formulação matemática do problema, objetivando um melhor desempenho no tempo de processamento.
\end{itemize}


\subsubsection{Meta-heurísticas}

Meta-heurísticas são métodos aproximados de resolução de problemas de Otimização Combinatória que fazem uso de mais de um processo heurístico na busca por soluções. São aplicadas em problemas complexos, mal-definidos ou com grande dificuldade computacional, em geral problemas NP-difíceis. Diferentemente das heurísticas, tais métodos conseguem explorar um grande espaço de busca, através de saltos aleatórios no mesmo. As meta-heurísticas servem para três propósitos principais: solucionar problemas de modo rápido, resolver problemas de grande porte, e conter outras heurísticas em seus procedimentos internos. Além disso, eles são simples de criar e implementar, e são muito flexíveis~\cite{Talbi:2009}. As meta-heurísticas também fazem uso da aleatoriedade ou pesquisa estocástica, ao contrário das heurísticas determinísticas. Esta seção baseia-se nas seguintes referências: Talbi~\cite{Talbi:2009}, Luke~\cite{Luke2009Metaheuristics} e  Rodrigues~\cite{rodrigues:1996}.


\paragraph{Busca Local Iterada}\subsubsection*{}\vspace{-1.5cm}

A busca local começa com uma solução inicial. A cada iteração, a heurística substitui a solução corrente por uma solução vizinha cuja função objetivo (FO) é melhor que a solução corrente. A busca termina quando todas soluções vizinhas são piores que a solução corrente, as soluções vizinhas da solução corrente fazem parte de um subconjunto do espaço de soluções. Na Figura~\ref{fig:LS} é apresentado um gráfico com uma curva representando as soluções e uma estratégia de seleção (seleção da solução vizinha).

A busca local pode ser vista como uma busca de melhores soluções em um grafo que representa o espaço de busca. Esse grafo pode ser definido como $G = (S,M)$, onde $S$ representa um conjunto de todas as soluções factíveis do espaço de busca e $M$ representa a relação de vizinhança. No grafo G, uma aresta $(i, j)$ será conectada a qualquer solução vizinha $s_{i}$ e $s_{j}$. Para uma dada solução $s$, o número de arestas associadas será $|N(s)|$ (número de soluções vizinhas).

\begin{figure}[ht]
\centering
\includegraphics[width=.5\textwidth]{./imagens/busca_local.eps}
\caption{Funcionamento do algoritmo de busca local em um determinado espaço de busca.}
\label{fig:LS}
\end{figure}

\subsubsection*{Seleção da melhor solução vizinha}

Muitas estratégias podem ser aplicadas na seleção da melhor solução vizinha (Figura~\ref{fig:Strategy-LS}):

\begin{itemize}
   \item \textbf{melhor encontrado (\textit{Best improvement}):} Nesta estratégia, a melhor solução vizinha (solução que possui o melhor valor de função objetivo) é selecionada. A vizinhança de soluções é avaliada de uma forma totalmente determinística. Por isso, a exploração das soluções vizinhas é exaustiva, todos os possíveis movimentos são utilizados para que seja encontrada a melhor solução. Este tipo de exploração pode consumir bastante tempo para um espaço muito grande de soluções vizinhas;
   \item \textbf{primeira melhora (\textit{First improvement}):} Esta estratégia consiste em escolher a primeira solução vizinha que é melhor que a solução corrente. Então, a solução corrente é imediatamente substituída por essa solução melhorada. Esta estratégia envolve uma avaliação parcial das soluções vizinhas. Em uma exploração cíclica, as soluções vizinhas são exploradas de modo determinístico seguindo uma dada ordem de geração de soluções. No pior caso (quando nenhuma melhoria é encontrada), uma avaliação completa das soluções vizinhas é realizada;
   \item \textbf{seleção aleatória (\textit{Random selection}):} Nesta estratégia, uma seleção aleatória é aplicada nas soluções vizinhas a fim de melhorar a solução corrente.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.95\textwidth]{./imagens/Estrategia-LS.eps}
\caption{Funcionamento do algoritmo de busca local em um determinado espaço de busca.}
\label{fig:Strategy-LS}
\end{figure}

A qualidade do ótimo local obtido pelo algoritmo de busca local depende de uma solução inicial. Como se pode gerar um ótimo local com tanta variabilidade, a busca local iterada pode ser utilizada para melhorar a qualidade dos sucessivos ótimos locais.

A busca local iterada é baseada no seguinte princípio: Primeiramente, uma busca local é aplicada em uma solução inicial. Assim, a cada iteração, é realizada uma perturbação do ótimo local obtido e, finalmente, uma busca local é aplicada na solução perturbada. A solução gerada é aceita como a nova solução corrente sob determinadas condições. Este processo é repetido durante um determinado número de iterações. O Algoritmo~\ref{code:BuscaLocalIterada} descreve o algoritmo de busca local.

\begin{algorithm}[htpb]
     $s_{*} \longleftarrow $ \textit{BuscaLocal($s_{0}$)} \Comment{Aplica um dado algoritmo de busca local}\;
     \Repita{Critério de parada satisfeito}{
     	  $s' \longleftarrow $ \textit{Perturba($s_{*}$)} \Comment{Perturba a solução corrente}\;
          $s'_{*} \longleftarrow $ \textit{BuscaLocal($s'$)} \Comment{Aplica a busca local na solução perturbada}\;
          $s_{*} \longleftarrow $ \textit{AceitaSolução($s_{*} $ , $ s'_{*}$)} \Comment{Critério de aceitação}\;
     }
     \Retorna{Melhor solução encontrada.}
\caption{Busca local iterada (\textit{Iterated local search}).}
\label{code:BuscaLocalIterada}
\end{algorithm}

Três elementos básicos compõem uma busca local iterada (Figura~\ref{fig:Strategy-ILS}):

\begin{itemize}
   \item \textbf{busca local:} qualquer meta-heurística (determinística ou estocástica) pode ser utilizada em conjunto com a busca local iterada;
   \item \textbf{método de perturbação:} a perturbação pode ser vista como um movimento aleatório da solução corrente. A perturbação deve manter alguma parte da solução original e fortemente perturbar a outra parte da solução para que seja possível explorar outras regiões do espaço de busca;
   \item \textbf{critério de aceitação:} define as condições que o novo ótimo local deve possuir para que ele possa substituir a solução corrente.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/busca_local_iterada.eps}
\caption{Funcionamento do algoritmo de busca local iterada em um determinado espaço de busca.}
\label{fig:Strategy-ILS}
\end{figure}


\paragraph{Algoritmo Genético}\subsubsection*{}\vspace{-1.5cm} \label{sec:GA}

Os Algoritmos Genéticos (GAs) foram originalmente propostos por Holland~\cite{Holland_1975}. Esses algoritmos utilizam o processo de evolução baseado na Teoria da Evolução de Darwin para resolver problemas, nessa teoria, os indivíduos mais adaptados sobrevivem. Nesse contexto, o termo \textbf{evolução} representa uma solução para o problema (formado por uma cadeia de genes); O termo \textbf{gene} representa uma certa característica da solução representada no cromossomo; O termo \textbf{Alelo} representa o valor de gene (usualmente 0 ou 1); A \textbf{Função de avaliação (\textit{Fitness})} representa o valor associado a um cromossomo para representar quão boa é a solução; A \textbf{População} é o conjunto de possíveis soluções (cromossomos); A \textbf{Geração} é a operação para se gerar uma nova população.

Existem muitas implementações de algoritmos genéticos para uma variedade de problemas, os componentes principais de algoritmos genéticos são os seguintes:
\begin{itemize}
  \item \textbf{solução codificada:} uma representação de cromossomo para as soluções;
  \item \textbf{população Inicial:} criação de uma população inicial de cromossomos;
  \item \textbf{função de avaliação:} medida de avaliação baseada na função objetivo;
  \item \textbf{seleção:} seleção natural de alguns cromossomos (pais) na população para
        geração de novos membros (filhos) na população;
  \item \textbf{operações genéticas:} operadores genéticos aplicados aos cromossomos cuja
        regra é criar novos membros (filhos) na população pelo cruzamento de genes de dois
        cromossomos (operações de cruzamento) ou pela modificação de genes de um cromossomo
        (operações de mutação);
  \item \textbf{substituição:} seleção natural dos membros da população que irão sobreviver;
  \item \textbf{parâmetro de seleção:} convergência natural de toda população que é
        globalmente melhorada a cada passo do algoritmo.
\end{itemize}

O desempenho do GA depende muito da concepção dos componentes supracitados e da escolha dos parâmetros como o tamanho da população, probabilidades de operações genéticas (taxa de cruzamento e taxa de mutação), e número de gerações.


\subsubsection*{Métodos de Seleção}

O mecanismo de seleção é um dos componentes principais dos algoritmos genéticos. O princípio do método de seleção é "quão melhor é um indivíduo, maior será a sua chance de ser um pai".
Através de métodos de seleção, os cromossomos (pais) são selecionados da população para serem combinados e formarem novos cromossomos (filhos), a fim de que sejam aplicadas novas operações genéticas. Dentre os métodos de seleção existentes na literatura, os principais são:

\begin{itemize}
    \item \textbf{seleção por roleta (\textit{roulette wheel selection}):} é o método mais comum de seleção, onde é designado a cada indivíduo uma seleção probabilística que é proporcional ao seu valor de avaliação. Seja $f_{i}$ o valor de avaliação baseado na função objetivo de um indivíduo $p_{i}$ na população $P$. A sua probabilidade de ser selecionado é $p_{i} = f_{i}/(\sum_{j=1}^{n} f_{i})$. E seja um gráfico de pizza onde cada indivíduo é posicionado no gráfico de acordo com o seu valor de avaliação. A seleção é realizada através da agulha de uma roleta que é posicionada em volta desse gráfico de pizza. A seleção de $\mu$ indivíduos é realizada através de $\mu$ giros independentes na seleção por roleta, como pode ser observado na Figura~\ref{fig:Selecion-Strategy} (a);
    \item \textbf{amostragem universal estocástica (\textit{stochastic universal sampling}):} esse tipo de seleção é semelhante a seleção por roleta, mas para selecionar $\mu$ indivíduos utiliza-se $\mu$ agulhas igualmente posicionadas. Nesta estratégia, em um único giro da roleta são selecionados $\mu$ indivíduos para reprodução, como pode ser observado na Figura~\ref{fig:Selecion-Strategy} (b);
    \item \textbf{seleção por torneio (\textit{tournament selection}):} é um método que consiste em sucessivas disputas para realizar a seleção. Primeiramente seleciona-se randomicamente $k$ indivíduos, onde o parâmetro $k$ é o tamanho do grupo do torneio. Um torneio é então aplicado nestes $k$ membros do grupo a fim de selecionar o melhor dentre eles. Para selecionar $\mu$ indivíduos, o procedimento de torneio é realizado $\mu$ vezes.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{./imagens/roleta.eps}
\caption{(a) seleção por roleta e (b) seleção por amostragem universal estocástica. Adaptado de Talbi~\cite{Talbi:2009}.}
\label{fig:Selecion-Strategy}
\end{figure}

\subsubsection*{Reprodução}

Uma vez que a seleção dos indivíduos é executada, a fase da reprodução conta com a aplicação dos operadores de reprodução, que são:

\begin{itemize}
	\item \textbf{Mutação:} é aplicada em um único indivíduo, a mutação representa pequenas mudanças em indivíduos previamente selecionados na população. A probabilidade $p_{m}$ define a probabilidade de mutação de cada elemento (gene) da solução. Geralmente pequenos valores são recomendados para essa probabilidade ($p_{m} \in [0.001, 0.01]$);
	\item \textbf{Recombinação e cruzamento:} recombina dois ou mais cromossomos para gerar novas soluções.
\end{itemize}


\subsubsection*{Elitismo}

O elitismo consiste em guardar as melhores soluções encontradas durante a busca de soluções. Onde uma população secundária pode ser utilizada para armazenar estas soluções de alta qualidade. O elitismo tem sido utilizado para prevenir a perda de soluções ótimas encontradas durante um processo de busca. Dessa forma, a população secundária não exerce nenhuma influência nas operações de busca da população corrente.


\subsubsection*{Estratégias de substituição}

A fase de substituição diz respeito à seleção dos sobreviventes tanto dos pais como das soluções filhas. Uma vez que o tamanho da população é constante, os indivíduos devem ser retirados de acordo com uma determinada estratégia de seleção, que são:

\begin{itemize}
    \item \textbf{substituição de gerações (\textit{generational replacement}):} abrange toda a população de tamanho $\mu$. A população descendente irá substituir sistematicamente a população original;
    \item \textbf{substituição de Regime Permanente (\textit{steady-state replacement}):} A cada geração do algoritmo, somente um descendente é gerado. E, a partir daí, o pior indivíduo da população original é substituído pelo descendente gerado.
\end{itemize}

\pagebreak

\paragraph{Recozimento Simulado (\textit{Simulated Annealing})}\subsubsection*{}\vspace{-1.5cm} \label{sec:SA}

O algoritmo de recozimento simulado é um método de busca local que aceita movimentos que pioram a solução para escapar de ótimos locais. Ele foi originalmente proposto por Kirkpatrick et al.~\cite{Kirkpatrick_Gelatt_Vecchi_1983}, e se fundamenta em uma analogia com a termodinâmica, ao simular o resfriamento de um conjunto de átomos aquecidos. Esta técnica começa a sua busca a partir de uma solução inicial qualquer. Os estados possíveis de um metal correspondem a soluções do espaço de busca. A energia em cada estado corresponde ao valor da função objetivo e a energia mínima (se o problema for de minimização ou máxima se for de maximização) corresponde ao valor de uma solução ótima local, ou possivelmente global.

O procedimento principal do Algoritmo~\ref{code:simulated} consiste em um laço de repetição que gera aleatoriamente, em cada iteração, um único vizinho $R$ de uma solução corrente $S$, que por sua vez foi gerada por uma permutação aleatória. A cada geração de um vizinho $R$ de $S$ é testada a variação do valor de função objetivo (custo), isto é, $\bigtriangleup \longleftarrow w(R) - w(S)$ para o problema de minimização, se $\bigtriangleup < 0$, o método aceita a solução e $R$ passa a ser a nova solução corrente. Caso $\bigtriangleup \ge 0$ a solução vizinha candidata também poderá ser aceita, mas nesse caso, com uma probabilidade $e^{-\bigtriangleup/T}$, onde $T$ é o parâmetro do método, chamado de temperatura, que regula a probabilidade de aceitação de pior custo. A probabilidade de se aceitar uma solução de pior custo depende de um parâmetro, chamado Temperatura, quanto menor for a Temperatura, menor será a probabilidade de se aceitar soluções de pior custo. A taxa de aceitação de movimentos de pior custo é, portanto, diminuída no decorrer das iterações.

A temperatura $T$ assume, inicialmente, um valor elevado $T_{max}$. Após um número fixo de iterações $N$ (o qual representa o número fixo de iterações necessárias para o sistema atingir o equilíbrio térmico em uma dada temperatura), a temperatura é diminuída gradativamente a cada iteração. Se a temperatura é diminuída de modo lento, melhores soluções são obtidas mas com um significativo tempo de processamento. O algoritmo pára quando a temperatura chega a zero (Temperatura de congelamento: $T_{min}$) e nenhuma solução que piore o valor da melhor solução é mais aceita, isto é, quando o sistema está estável.

\begin{algorithm}[htpb]
     $T \longleftarrow T_{max}$ \Comment{Temperatura inicial}\;
     $S \longleftarrow$ uma solução inicial\;
     \textit{MelhorSolução} $ \longleftarrow S$\;
     \Repita{Critério de parada satisfeito}{
        \Repita{Condição de equilíbrio}{
          $R \longleftarrow k$ uma perturbação aleatória em $S$\;
          $\bigtriangleup \longleftarrow w(R) - w(S)$\;
          $valor \longleftarrow $ um número aleatório entre 0 e 1\;
          \Se{$w(R) \le w(S)$ ou $valor < e^{-\bigtriangleup/T}$}{
              $S \longleftarrow R$\;
          }
          \Se{$w(S) \le w(MelhorSolucao)$}{
              \textit{MelhorSolução} $ \longleftarrow S$\;
          }
       } \Comment{Exemplo: um dado número de iterações executadas a cada mudança de temperatura $T$}\;
       Atualize a temperatura $T$\;
     } \Comment{Exemplo: $T < T_{min}$}\;
     \Retorna{\textit{MelhorSolução}}.
\caption{Recozimento simulado (\textit{Simulated Annealing}).}
\label{code:simulated}
\end{algorithm}

\pagebreak

\paragraph{Busca Tabu (\textit{Tabu Search})}\subsubsection*{}\vspace{-1.5cm} \label{sec:TS}

A Busca Tabu, proposta por Glover~\cite{Glover:1438112}, é uma meta-heurística que guia uma heurística de busca local de forma a superar a otimalidade local, ou seja, o algoritmo evita retornar a um ótimo local visitado previamente, superando assim o ótimo local e atingindo um resultado ótimo ou próximo do ótimo global. Para isso, o algoritmo mantém um histórico de trajetórias de busca recentes (conhecida como a \textbf{lista tabu}) durante um determinado período de tempo (prazo tabu), dessa forma, a busca move-se, a cada iteração, para a melhor solução na vizinhança, não aceitando movimentos que levem a soluções já visitadas (soluções armazenadas na lista tabu) a fim de evitar ciclos, o Algoritmo~\ref{code:tabu} descreve os passos da Busca Tabu.

Os três principais fundamentos da Busca Tabu consistem em:

\begin{itemize}
    \item uso de estrutura de memória flexível que facilita a implementação de múltiplos critérios de avaliação e de processamento de informação histórica;
    \item mecanismo de controle que permita a manipulação de restrições e liberações de condições de busca para períodos de tempo variados;
    \item possibilidade de diferentes estratégias de busca para curto, médio e longo prazo (busca agressiva ou diversificada).
\end{itemize}

As restrições tabu também podem ser manipuladas por critérios de aspiração. Um critério de aspiração comumente utilizado é o critério que consiste em aceitar aquele movimento que produz uma solução melhor que a solução corrente do algoritmo, outro critério de aspiração pode ser um movimento que produz uma solução melhor entre um conjunto de soluções que possuem um determinado atributo.

\begin{algorithm}[htpb]
     $s \longleftarrow s_{0}$ \Comment{Solução inicial}\;
     Crie uma lista tabu\;
     \Repita{Critério de parada satisfeito}{
     	  Encontre um vizinho admissível $s'$ \Comment{vizinho que não esteja na lista tabu ou que satisfaça o critério de aspiração estabelecido}\;
          $s \longleftarrow s'$\;
          Atualize a lista tabu\;
          Atualize, se desejado, o critério de aspiração\;
     }
     \Retorna{$s$.}
\caption{Busca Tabu (\textit{Tabu Search}).}
\label{code:tabu}
\end{algorithm}


\paragraph{GRASP}\subsubsection*{}\vspace{-1.5cm} \label{sec:GR}

A meta-heurística GRASP (Greedy Randomized Adaptive Search Procedure) trata-se de um algoritmo iterativo guloso utilizado em muitos problemas de otimização combinatória. Este algoritmo foi proposto por Feo et al.~\cite{Feo198967} em 1989. Cada iteração do algoritmo GRASP contém dois passos: fase construtiva e fase de busca local.

Na fase construtiva, uma solução factível é construída através de um algoritmo guloso aleatório, enquanto que na próxima fase, uma heurística de busca local é aplicada a partir da solução construída. O algoritmo guloso deve ser aleatório pois deve ser capaz de gerar várias soluções. Caso contrário, o procedimento de busca local pode ser aplicado apenas uma vez. Este esquema é repetido durante um determinado número de iterações e, ao final da execução, a melhor solução encontrada é retornada~\cite{Talbi:2009}. O GRASP pode ser descrito através dos passos apresentados no Algoritmo~\ref{code:grasp}.

\begin{algorithm}[htpb]
     \Repita{Número máximo de iterações}{
     	  $s \longleftarrow $ uma solução gerada pela heurística gulosa aleatória\;
     	  $s' \longleftarrow $ resultado da busca local aplicada na solução $s$\;
     	  \Se{$s' $  for melhor que $s$}{
     	      $s \longleftarrow s'$\;
     	  }
     }
     \Retorna{$s$}
\caption{GRASP.}
\label{code:grasp}
\end{algorithm}

\pagebreak

\paragraph{Busca Dispersa (\textit{scatter search})}\subsubsection*{}\vspace{-1.5cm} \label{secSS}

A busca dispersa é um método evolutivo que vem sendo aplicado com sucesso em alguns problemas de otimização combinatória. O princípio desse método é a combinação de soluções de modo a gerar outras soluções. O método é inicializado a partir de uma população inicial $Pop$ satisfazendo o critério de diversidade e qualidade. Um conjunto de referência\footnotetext{O conjunto de referência é um conjunto com as melhores e diversificadas soluções já encontradas na população, por exemplo, um conjunto de referência pode ser criado com $x$ melhores soluções da população e $y$ soluções da população com alto grau de diversidade.} de soluções é criado através da escolha de soluções que sejam representativas para a população. As soluções selecionadas são então combinadas para servirem de soluções iniciais para uma heurística de melhoria de soluções. De acordo com o resultado dessa heurística, o conjunto de referência de soluções é atualizado de modo que ele guarde soluções diversificadas e de alta qualidade.

A busca dispersa envolve diferentes procedimentos permitindo a geração de uma população inicial, construir e atualizar o conjunto de referências, combinar as soluções de tal conjunto, melhorar as soluções combinadas e assim em diante. O Algoritmo~\ref{code:SS} apresenta a descrição detalhada do funcionamento da busca dispersa.

\begin{algorithm}[htpb]
     Inicie uma população $Pop$ utilizando um método de geração diversificada\;
     Aplique um método de melhoria na população\;
     Atualize o conjunto de referência\;
     \Enqto{\textit{NovasSoluções} = $1$}{
          \textit{NovasSoluções} $\longleftarrow 0$\;
          Gere um subconjunto de soluções a partir das soluções do conjunto de referência\;
          \Enqto{existirem soluções no subconjunto gerado}{
	     	  Aplique o método de combinação das soluções do subconjunto\;
	     	  Aplique um método de melhoria a partir das soluções combinadas\;
	     	  Atualize o conjunto de referência\;
     	  }
     	  \Se{conjunto de referência alterado}{
     	      \textit{NovasSoluções} $ \longleftarrow 1$\;
     	  }
     }
     \Retorna{Melhor solução ou o melhor conjunto de soluções}
\caption{Busca dispersa (\textit{Scatter Search}).}
\label{code:SS}
\end{algorithm}


\paragraph{Reconexão de Caminhos (\textit{Path Relinking})}\subsubsection*{}\vspace{-1.5cm} \label{secPR}

A técnica de Reconexão de caminhos foi originalmente proposta por Glover et al.~\cite{Glover00} para a diversificação do algoritmo de busca dispersa. Esta técnica permite explorar caminhos que ligam duas soluções elite encontradas pela busca dispersa, entretanto, esta estratégia pode ser generalizada e aplicada a outras meta-heurísticas para gerar boas soluções. A ideia principal desta técnica é de gerar e explorar uma trajetória no espaço de busca conectando uma solução inicial $s$ e uma solução guiada ou de destino $s'$. O caminho entre duas soluções no espaço de busca (vizinhança) geralmente resultam em soluções que compartilham atributos comuns das soluções iniciais. O Algoritmo~\ref{code:Path-Relinking} apresenta o esquema de funcionamento do algoritmo de reconexão de caminhos, onde, a cada iteração, o melhor movimento em termos de função objetivo é escolhido e há uma diminuição da distancia $d$ entre duas soluções. Este procedimento é repetido até que a distancia entre as duas soluções seja $0$. A melhor solução encontrada na trajetória é retornada pelo algoritmo.

\begin{algorithm}[htpb]
	 \Entrada{solução inicial $s$ e solução guiada $s'$}
     $x \longleftarrow s$\;
     \Enqto{\textit{dist($x$,$s'$)} $\neq$ $0$}{
          Encontre o melhor movimento $m$ que diminua a \textit{dist($x \oplus m$,$s'$)}\;
          $x \longleftarrow x \oplus m $ \Comment{Aplica o movimento $m$ na solução $x$}\;
     }
     \Retorna{Melhor solução encontrada na trajetória entre $s$ e $s'$}
\caption{Reconexão de Caminhos (\textit{Path Relinking}).}
\label{code:Path-Relinking}
\end{algorithm}

Os principais questionamentos do algoritmo de reconexão de caminhos são~\cite{Talbi:2009}:

\begin{itemize}
    \item \textbf{seleção do caminho:} o que deve ser considerado na geração do caminho. Uma heurística pode ser utilizada para gerar o caminho que deve ser utilizado para minimizar a distância até a solução guiada. Para isso, uma distância $d$ deve ser definida no espaço de busca associado ao problema. A complexidade computacional para esse procedimento deve ser levada em consideração;
    \item \textbf{operações intermediárias:} que operações devem ser aplicadas a cada passo da geração do caminho. Algumas soluções selecionadas no caminho podem ser consideradas. Por exemplo, para cada solução intermediária no caminho, um procedimento de busca local pode ser aplicado a fim de melhorar a qualidade da solução.
\end{itemize}

Além disso, para cada par de soluções de $s$ e $s'$, existem várias alternativas diferentes para seleção da solução inicial e solução guiada (Figura~\ref{fig:PR-Strategies}):

\begin{itemize}
   \item \textbf{caminho adiantado (\textit{forward}):} a pior solução entre $s$ e $s'$ é utilizada como solução inicial;
   \item \textbf{caminho reverso (\textit{backward}):} a melhor solução entre $s$ e $s'$ é utilizada como solução inicial. Como a vizinhança da solução inicial é mais explorada do que a vizinhança da solução guiada, a estratégia de caminho reverso é em geral melhor do que a estratégia do caminho adiantado;
   \item \textbf{reconexão do reverso com o adiantado (\textit{back and forward relinking}):} dois caminhos são construídos em paralelo, utilizando alternativamente a solução $s$ como solução inicial e guiada. Apesar desta estratégia apresentar boas soluções, este método adiciona uma sobrecarga no tempo de computação;
   \item \textbf{reconexão mista (\textit{mixed relinking}):} assim como na estratégia de reconexão do reverso com o adiantado, dois caminhos são construídos em paralelo partindo de $s$ até $s'$, mais agora, a solução guiada é uma solução intermediária $m$, que está localizada a uma mesma distância de $s$ e $s'$. Esta estratégia paralela pode reduzir o tempo de execução.
\end{itemize}

\begin{figure}[htpb]
\centering
\includegraphics[width=.55\textwidth]{./imagens/PR-Strategies.eps}
\caption{\footnotesize{Diferentes estratégias de Reconexão de Caminhos em termos das soluções inicial e guiada. Adaptado de Talbi~\cite{Talbi:2009}.}}
\label{fig:PR-Strategies}
\end{figure}


\section{Teoria de Escalonamento} \label{ProbEsc}

De acordo com Rodrigues~\cite{rodrigues:2009}, problemas de escalonamento podem ser definidos como sendo a designação ou alocação de determinados recursos a determinadas atividades em função do tempo. Tal alocação sobre o tempo envolve um processo de tomada de decisão que visa otimizar um ou mais critérios de medida de desempenho. Devido ao fato de um dos primeiros problemas modelados como sendo de escalonamento envolver a otimização da produção de uma fábrica, virou consenso definir de maneira geral um problema de escalonamento como sendo a alocação de tarefas a máquinas ou processadores de tal forma a otimizar algum critério de produção. Tais critérios são modelados como uma função matemática de maximização ou minimização chamada de função objetivo.

Existem muitos problemas de escalonamento, variando de acordo com o tempo de processamento, tipos e quantidade de restrições  dos elementos a serem escalonados, condições de execução e critério de otimização, isto é, o número de máquinas pode variar e eles podem ser iguais ou diferentes, os elementos podem ou não ter tempo de início e término bem-definidos, pode haver ou não interrupção nas tarefas (preempção), entre outros.

Para os problemas de escalonamento considerados nesta seção o número de tarefas e o número de máquinas são finitos. O número de tarefas é denotado por $n$ e o número de máquinas é denotado por $m$. Geralmente, $j$ refere-se a uma tarefa enquanto que $i$ refere-se a uma determinada máquina. Se uma tarefa requer uma determinado tipo de processamento ou operação, então o par ($i, j$) refere-se a ao processamento ou operação de uma tarefa $j$ na máquina $i$~\cite{brucker:2006}, \cite{pinedo:2012}. Sejam $m$ as máquinas $M_{j}(j = 1, ..., m)$ que devem processar $n$ tarefas $J_{i}(i = 1, ..., n)$, um escalonamento é para cada tarefa uma alocação de um ou mais intervalos a uma ou mais máquinas.


\subsection{Representação e notação}

Graham et al.~\cite{Graham_Lawler_Lenstra_Kan_1979} introduziram um esquema de classificação para problemas de escalonamento em termos da notação de três campos  {\boldmath $\alpha | \beta | \gamma$ } onde {\boldmath $ \alpha $} especifica o \textbf{ambiente de processamento} que possui somente uma entrada, {\boldmath $ \beta $} especifica os detalhes das \textbf{características das tarefas} e restrições de escalonamento, pode ter muitas ou nenhuma entrada e {{\boldmath $ \gamma $} especifica a \textbf{função objetivo (FO)} a ser otimizada (\textit{critério de otimalidade}), geralmente tendo somente uma entrada.

Um escalonamento pode ser representado pelo \textbf{Gráfico de Gantt} (Figura~\ref{fig:Gantt-chart-example}), que mostra um exemplo de saída \textbf{orientado-a-máquina} (Figura~\ref{fig:Gantt-chart-example} (a)) onde as tarefas são representadas por caixas retangulares em uma representação do primeiro quadrante do plano cartesiano - o eixo das abcissas representa o tempo de processamento e o eixo das ordenadas representa as máquinas. Outra representação do gráfico de Gantt é a representação \textbf{orientado-a-tarefa} (Figura~\ref{fig:Gantt-chart-example} (b)), onde a diferença é a troca entre as tarefas e máquinas.

\begin{figure}[ht]
\centering
\includegraphics[width=.9\textwidth]{./imagens/Gantt_Chart2.eps}
\caption{Exemplo de representação no Gráfico de Gantt: (a) orientado-a-máquina e (b) orientado-a-tarefa~\cite{rodrigues:2009}.}
\label{fig:Gantt-chart-example}
\end{figure}


\subsubsection{Ambiente de processamento}

Os principais ambientes de processamento em um escalonamento e suas notações são definidas a seguir:
\begin{itemize}
 \item \textbf{ambiente monoprocessado:} quando há um único processador no sistema. A notação utilizada é $1$;

 \item \textbf{processadores ou máquina paralelas idênticas:} quando existem $m$ máquinas idênticas em paralelo. Utiliza-se a notação $P_{m}$ se o número de processadores é fixo ($m$ é uma constante), e utiliza-se a notação $P$ se o número de processadores é parte da entrada ($m$ é uma variável);

 \item \textbf{processadores ou máquinas paralelas uniformes:} quando existem $m$ máquinas paralelas com velocidades diferentes. A notação utilizada neste caso é $Q$ e $Q_{m}$;

 \item \textbf{processadores ou máquinas paralelas não-relacionadas:} quando existem $m$ máquinas em paralelo com desempenhos dependentes da tarefa a ser executada. A notação utilizada neste caso é $R$ e $R_{m}$;

 \item \textbf{processadores ou máquinas de propósito geral: } quando as $m$ máquinas são divididas em subconjuntos $\mu$, a notação desses subconjuntos é $PMPM$ se as máquinas forem idênticas. Se as máquinas forem paralelas uniformes, a notação é $QMPM$. E, se as máquinas paralelas forem não-relacionadas, a notação é $RMPM$. A notação utilizada para os processadores de propósito geral é $MPM$;

 \item \textbf{\textit{flow shop}: } quando existe a mesma sequência de máquinas para cada tarefa. Dessa forma, considera-se $m$ máquinas em série, cada tarefa deve ser processada e cada uma dessas $m$ máquinas. Todas as tarefas devem seguir a mesma configuração de processamento, ou seja, elas devem ser processadas primeiramente na máquina $1$, depois na máquina $2$ e assim sucessivamente. Depois de finalizar a sua execução em uma máquina, a tarefa entra na fila para ser executada na próxima máquina. Geralmente, todas as filas são organizadas por ordem de chegada (\textit{First In First Out - FIFO}). A notação utilizada é $F$ e $F_{m}$;

 \item \textbf{\textit{job shop}: } quando existem máquinas diferentes e em ordem diferente em cada tarefa. A notação utilizada é $J$ e $J_{m}$;

 \item \textbf{\textit{open shop}: } quando a tarefa é executada em cada máquina exatamente uma vez em cada sequência, esta sequência é diferente para cada tarefa. A notação utilizada é $O$ e $O_{m}$.
\end{itemize}


\subsubsection{Características das tarefas}

Cada \textbf{tarefa (do inglês, \emph{job} ou \emph{task})} pode ter muitas restrições associadas, como as seguintes:
\begin{itemize}
 \item \textbf{data de chegada ou de disponibilidade (\textit{release date}):} define o momento em que a tarefa pode começar a ser executada. A notação utilizada é $r_{j}$;

 \item \textbf{data de término sugerida (\textit{due date}):} indica o tempo que a tarefa dever ser finalizada, notação $d_{j}$, sob pena de sofrer alguma penalidade caso ultrapasse tal tempo;

 \item \textbf{data de término obrigatória (\textit{deadline}):} indica o tempo que cada tarefa deve ser finalizada, notação $D_{j}$, não sendo permitido ultrapassar tal tempo;

 \item \textbf{tempos de processamento (\textit{processing time}):} restringe o tempo de processamento de cada tarefa, notação $p_{j}$, por exemplo, quando $p_{j} = p$, significa que todas as tarefas possuem o mesmo tempo de processamento, igual a $p$, quando $p_{j} = 1$, significa que todas as tarefas têm o mesmo tempo de processamento igual a 1, mas quando a notação $p_{j}$ é omitida da descrição do problema, as tarefas podem possuir tempos de processamento quaisquer;

 \item \textbf{peso (\textit{weight}):} que pode representar prioridades iguais ou diferentes. A notação utilizada é $w_{j}$;

 \item \textbf{preempção (\textit{preemption})} indica se uma preempção (interrompe e retoma sua execução) é permitida ou não. A notação utilizada é $pmtn$;

 \item \textbf{sem-espera \textit{no-wait}:} indica que a tarefa não pode ficar em estado de espera depois de iniciada sua execução. Somente para \textit{flow shops}. A notação utilizada é $nwt$;

 \item \textbf{restrição no número de tarefas:} restringe o número de tarefas, ou seja, $nbr_{j} = 5$ indica que existem no máximo $5$ tarefas a serem processadas. A notação utilizada é $nbr$;

 \item \textbf{restrição de precedência (\textit{precedence constraints}):} essas restrições podem aparecer nos ambientes mono e multi-processado, sendo que uma ou mais tarefas devem ser completadas antes que outra tarefa possa começar o seu processamento. Existem casos especiais de restrição de precedência: se cada tarefa tem pelo menos um predecessor e pelo menos um sucessor, as restrições são definidas como \textit{chains}. Se cada tarefa tem pelo menos um sucessor, as restrições são definidas como \textit{intree}. Se cada tarefa tem pelo menos um predecessor as restrições são definidas como \textit{outtree}. A notação utilizada é $prec$;

 \item \textbf{sequência dependente de tempos de preparação (\textit{sequence dependent setup times}):} onde $s_{jk}$ representa uma sequência dependente de tempos de preparação das tarefas $j$ e $k$, $S_{0k}$ denota o tempo de preparação para a tarefa $k$ se a tarefa $k$ é a primeira na sequência e $s_{j0}$ se a tarefa $j$ é a última da sequência. Se o tempo de preparação entre as tarefas $j$ e $k$ depende da máquina, então o índice $i$ é incluído, ou seja, $s_{ijk}$. Se $s_{jk}$ não aparecer no problema, ou seja, se $s_{jk}$ não aparecer no campo $\beta$, todos os tempos de preparação possuem o valor $0$. A notação utilizada é $s_{jk}$;

 \item \textbf{processamento em lotes(\textit{batch processing}):} onde uma máquina deve ser capaz de processar um número de tarefas, $b$, simultaneamente, ou seja, pode processar um lote de $b$ tarefas ao mesmo tempo. Os tempos de processamento de todas as tarefas no lote não devem ser os mesmos e o lote todo é finalizado somente quando a última tarefa do lote é completada, implicando que o tempo de processamento de todo o lote é determinado pela tarefa com o maior tempo de processamento. Se $b=1$, então o problema é reduzido ao problema convencional de escalonamento. Outro caso especial é o $b=\infty$, ou seja, não há limite no número de tarefas que a máquina pode processar ao mesmo tempo.

 Utilizam-se as notações $p-batch$, quando o comprimento do lote for igual ao maior dos tempos de processamento dentre todas as tarefas, e a notação $s-batch$, quando o comprimento do lote for igual a soma dos tempos de processamento de todas as tarefas.
\end{itemize}

É chamada \textbf{janela de tempo} (\textit{time window}), um intervalo de tempo determinado por uma data de início e uma data de término. A janela de tempo de uma determinada tarefa, para que seja executada em tempo, é definida por sua data de chegada e por sua data de término sugerida. Uma tarefa pode ser executada em qualquer máquina com mesmo desempenho ou diferentemente em cada máquina, o que pode tomar mais ou menos tempo para ser executada. Neste caso, $p_{ij}$ representa o tempo de processamento que a tarefa $J_{j}$ demora pra ser processada na máquina $M_{i}$. O critério de otimização ou função objetivo $f_{j}(t)$ representa o custo induzido pela tarefa $J_{j}$ quando é executada em um processador até o tempo $t$.


\subsubsection{Critério de otimalidade}

De acordo com Brucker~\cite{brucker:2006}, existem dois tipos de função de custo, que são: $f_{max}(C) = max\{f_{i}(C_{i})|i = 1,...,n\}$ e $\sum f_{i}(C) = \sum_{i=1}^{n} f_{i}(C_{i})$ chamados de funções objetivo de gargalo (\textit{bottleneck objectives}) ou do tipo MinMax (MaxMin), e funções objetivo de soma total (\textit{sum objectives}), respectivamente. O objetivo é achar um escalonamento factível que minimize uma função de custo obedecendo a certos critérios de otimização. Existem determinadas \textbf{funções objetivos clássicas}, a maioria delas sendo uma \textbf{função regular}, que possui um comportamento não-decrescente em relação aos tempos de completude das tarefas. O tempo de completude da tarefa $j$ na máquina $i$ é denotado por $C_{ij}$. Se a tarefa não for dependente da máquina, o tempo que a tarefa $j$ sai do sistema, ou seja, o tempo que a tarefa finaliza o seu processamento na máquina onde foi processada, é denotado por $C_{j}$.

A seguir serão apresentados exemplo de funções regulares que consideram escalas de tempo, conhecidas como \textbf{critérios proporcionais}, que são~\cite{rodrigues:2009}:

\begin{itemize}
   \item \textbf{maior tempo de completude (\textit{makespan})} (Notação: $C_{max}$) refere-se ao tempo de completude da última tarefa a terminar sua execução, ou de outra forma, maior tempo de completude dentre todas as tarefas executadas. $C_{max} = max\{C_{1}, ..., C_{m}\}$. Deseja-se minimizar $C_{max}$, pois um \textit{makespan} mínimo geralmente significa uma maior utilização da máquina;

   \item \textbf{máxima latência (\textit{maximum lateness})} (Notação: $L_{max}$) é definida como $L_{j} = C_{j} - d_{j}$, que será um valor positivo se a tarefa $J_{j}$ for executada com atraso, será um valor negativo se a tarefa for antecipada ou, senão, será um valor nulo. A função de máxima latência ($L_{max}$), então, retorna o valor do maior atraso possível ou menor antecipação se não houver atrasos, considerando todas as tarefas executadas. $L_{max} = max\{L_{1}, ..., L_{n}\}$, onde deseja-se minimizar o $L_{max}$;

   \item \textbf{tempo total de completude (\textit{total completion time})} (Notação: $\sum C_{j}$ ou $\sum w_{j}C_{j}$) soma de todos os tempos de completude das tarefas (ponderadas ou não), onde deseja-se minimizar $\sum C_{j}$ ou $\sum w_{j}C_{j}$;

   \item \textbf{tempo total de atraso (\textit{tardiness}) (Notação: $\sum T_{j}$ ou $\sum w_{j} T_{j}$)} trata-se da soma de todos os tempos de atraso das tarefas (ponderadas ou não). Dessa forma, o atraso assume um valor positivo se as tarefas forem atrasadas, caso contrário, o atraso assume o valor $0$. Sendo $T_{j} = max\{L_{j},0\}$, onde deseja-se minimizar $\sum T_{j}$ ou $\sum w_{j} T_{j}$.
\end{itemize}

Também existem funções objetivo que não dependem diretamente do tempo, sendo conhecidos como \textbf{critérios permanentes}, que são:

\begin{itemize}
   \item \textbf{número de tarefas tardias} (Notação: $\sum U_{j}$ ou $\sum w_{j} U_{j}$) é o número total de tarefas executadas com atraso (ponderadas ou não), onde $U_{j}$ é uma penalidade unitária caso a tarefa esteja atrasada (e nula caso contrário), como no exemplo a seguir:

   \begin{equation} U_{j} = \left \lbrace \begin{array}{l} 1 \text{ se } C_{j} > d_{j} \\ 0 \text{ caso contrário} \\ \end{array} \right .\end{equation}

\end{itemize}

A função objetivo que envolve a minimização de atraso pertence a classe de funções objetivo que possui medidas \textbf{regulares} de desempenho. Uma função objetivo possui uma medida de desempenho regular quando é não-decrescente em $C_{1}, ..., C_{n}$. Pesquisas recentes consideram cada vez mais o estudo de funções objetivo que são \textbf{não-regulares}, como por exemplo, a que representa penalidades de antecipação (ponderadas ou não). A antecipação assume um valor positivo se as tarefas forem antecipadas, caso contrário, o valor de antecipação assume o valor $0$. Desta forma, a penalidade de antecipação é não-crescente em $C_{j}$ e pode ser formalmente descrita como segue:

\begin{itemize}
   \item \textbf{tempo total de antecipação (\textit{earliness}) (Notação: $\sum E_{j}$ ou $\sum w_{j} E_{j}$)} trata-se da soma de todos os tempos de antecipação das tarefas (ponderadas ou não). Desta forma, a antecipação assume um valor positivo se as tarefas forem antecipadas, caso contrário, o valor de antecipação é valor $0$. Sendo $E_{j} = max{d_{j} - C_{j}, 0}$, onde deseja-se minimizar $\sum E_{j}$ ou $\sum w_{j} E_{j}$.
\end{itemize}

Para atender ao conceito surgido nas indústrias de produção sem folga, ou seja, de produto produzido o mais próximo possível da data de entrega (do inglês \emph{Just-in-Time}), aplica-se uma combinação dos critérios de antecipação e atraso anteriormente descritos, e, desta forma, a função objetivo consiste na soma das tarefas escalonadas com antecipação e atraso, ponderadas ou não, tal como segue:

\begin{equation}
   \sum_{j=1}^{n}{\alpha_{j} E_{j}} + \sum_{j=1}^{n}{\beta_{j} T_{j}}.
\end{equation}

\noindent Observa-se que na formulação acima, as tarefas são ponderadas e o peso associado à antecipação da tarefa $j$ ($\alpha_{j}$) difere do peso associado ao atraso da tarefa $j$ ($\beta_{j}$). Se os pesos forem iguais para ambas penalidades considerando a mesma tarefa, então, basta isolar a constante do somatório.

Um exemplo para o escalonamento com penalidades de antecipação e atraso em ambiente de máquinas paralelas idênticas é apresentado na Figura~\ref{fig:Gantt} onde, na Figura~\ref{fig:Gantt} (a) é apresentado um exemplo de instância com $6$ tarefas para o problema com seus respectivos valores para tempos de processamento ($p_{j}$), prazos ($d_{j}$), penalidades de antecipação ($\alpha_{j}$), penalidades de atraso ($\beta_{j}$), tempo de completude ($C_{j}$) das tarefas, valores de antecipação ($E_{j}$) e atraso ($T_{j}$) das tarefas, e os valores da antecipação ponderada ($\alpha_{j} E_{j}$) e do atraso ponderado das tarefas ($\beta_{j} T_{j}$) e na Figura~\ref{fig:Gantt} (b) pode-se observar como fica a representação do escalonamento em três máquinas para essa instância. O valor de antecipação é obtido pela diferença entre o prazo e o tempo de completude, e o valor de atraso é obtido através de diferença entre o tempo de completude da tarefa e o prazo, caso o resultado de uma dessas diferenças seja negativo, é atribuído o valor $0$ no lugar do resultado negativo. Ao final, o peso ou penalidade de cada tarefa é multiplicado com o seu respectivo valor de antecipação ($E_{j}$) ou atraso ($T_{j}$) e, depois esses resultados são somados obtendo assim o valor total de antecipação ponderada e de atraso ponderado das tarefas.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./imagens/GanttChart.eps}
\caption{(a) Exemplo de uma instância de $6$ tarefas para o problema de escalonamento com antecipação e atraso (b) Representação do escalonamento através do Gráfico de Gantt orientado-a-máquina.}
\label{fig:Gantt}
\end{figure}


\subsection{Hierarquia de complexidade}

Os problemas de escalonamento de tarefas são problemas de \textbf{otimização combinatória}. Existem inúmeros problemas de escalonamento, classificados em diferentes classes de \textbf{complexidade computacional}. Tal complexidade determina a natureza do algoritmo a ser desenvolvido e, muitas vezes, um algoritmo para um determinado problema de escalonamento pode ser aplicado para a solução de outro problema, pois muitos desses problemas tratam-se de casos particulares ou generalizações de outros. Por exemplo, o problema $1||\sum C_{j}$ é um caso especial do problema $1||\sum w_{j} C_{j}$, dessa forma, um algoritmo para $1|| \sum w_{j} C_{j}$ pode também ser utilizado para solucionar o problema $1||\sum C_{j}$. Na terminologia de complexidade é dito que o problema $1||\sum C_{j}$ é redutível ao problema $1||\sum w_{j} C_{j}$. Que é denotado por suas \textbf{hierarquias de complexidade}~\cite{pinedo:2012},\cite{rodrigues:2009},\cite{brucker:2006}:

\begin{equation}
    1||\sum C_{j} \propto 1||\sum w_{j} C_{j}.
\end{equation}

%\noindent Baseado neste conceito, uma série de reduções pode ser estabelecida. Por exemplo,

%\begin{equation}
 %    1||\sum C{j} \propto 1||\sum w_{j} C_{j} \propto P_{m}||\sum w_{j} C_{j} \propto Q_{m}|prec|\sum w_{j} C_{j}.
%\end{equation}

\noindent Entretanto, também podem existir muitos problemas que não são comparáveis uns com os outros. Por exemplo, $P_{m}||\sum w_{j} T_{j}$ não é comparável com o problema $J_{m} || C_{max}$.

%Em comparação com as diferentes complexidades de problemas de escalonamento, é interesse saber como uma pequena mudança no problema pode afetar a sua complexidade.

Na Figura~\ref{fig:Sched-complexity} (a) são apresentadas as reduções elementares para os principais ambientes de processamento; na Figura~\ref{fig:Sched-complexity} (b) são apresentados os diagramas de inclusão para algumas restrições de processamento; e na Figura~\ref{fig:Sched-complexity} (c) são apresentadas as reduções elementares para as funções objetivo.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{./imagens/Sched-Complexity.eps}
\caption{Hierarquias de complexidade dos problemas de escalonamento determinísticos: (a) relação de complexidade entre os ambientes de processamento (b) relação entre as principais características das tarefas em um escalonamento (c) relação de complexidade entre as funções objetivo clássicas (d) relação de complexidade entre as funções objetivo com antecipação e atraso.}
\label{fig:Sched-complexity}
\end{figure}

